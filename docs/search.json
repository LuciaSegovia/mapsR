[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mapsR: A guide to data analysis with R",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#about-this-manual",
    "href": "index.html#about-this-manual",
    "title": "mapsR: A guide to data analysis with R",
    "section": "About this manual",
    "text": "About this manual\nThis manual is designed for absolute beginners who are interested in using R and RStudio. The manual is an adaptation of materials for statistical analysis of soil and related data from agricultural and environmental surveys and experiments developed by the Capacity for Conservation Agriculture Research (CEPHaS) project and made available to all for use, without warranty or liability. The CEPHaS project is funded by the UK Research and Innovation Global Challenges Research Fund (UKRI GCRF).\nComplilation of this manual is made possible by the Micronutrient Action Poicy Support (MAPS) project team, funded by the Bill and Melinda Gates Foundation. This complilation is made available to all for use, without warranty or liability."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "mapsR: A guide to data analysis with R",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis manual is a collaborative effort between the CEPHaS and MAPS projects. We would like to thank the following people for their contributions to this manual: Liberty Mlambo, Murray Lark, Louise E. Ander, Hakunawadi Pswarayi, Tineka Blake, Chris Chagumaira"
  },
  {
    "objectID": "index.html#who-is-this-manual-for",
    "href": "index.html#who-is-this-manual-for",
    "title": "mapsR: A guide to data analysis with R",
    "section": "Who is this manual for?",
    "text": "Who is this manual for?\nThe goal of this manual is to provide a comprehensive introduction to these powerful technologies and to teach you how to use them to better understand your data and collaborate with others on your project.\nThroughout this manual, you will learn how to install and set up R and RStudio on your computer, as well as how to use them to perform data analysis, create visualizations, and manage your code. The manual includes step-by-step instructions, examples, and practice exercises to help you master these technologies.\nWhether you are a researcher, data scientist, or statistician, this manual will provide you with the skills and knowledge you need to start using R and RStudio, to better understand your data and collaborate with others on your project.\nIt is important to note that this manual is not a comprehensive guide to R and RStudio but rather an introduction, designed to give you the foundational knowledge to start working with these technologies. There are many other resources available for learning more about these technologies, including online tutorials, forums, and documentation.\nWe hope you find this manual helpful and that it empowers you to work with these powerful tools."
  },
  {
    "objectID": "data_types.html#introduction",
    "href": "data_types.html#introduction",
    "title": "2  Data Types",
    "section": "Introduction",
    "text": "Introduction\nThe objective of this section is to provide information on the topic under consideration, along with examples and exercises. You should be able to work through it in R or R studio. This particular section requires no additional functions or packages to be loaded.\nThe specific objective of the material in this section is to introduce you to the principal data types and data structures in R. By the end you should have a better understanding of the R scripts, and should be better-placed to start developing and editing scripts yourself. The particular topics we shall cover are:\n\nBasic data types in R: numeric, character, and logical\nData structures: vectors.\n\nFactors\nData structures: Matrices, making matrices, matrix operations\nData structures: Dataframes\nData structures: Lists\n\nThe principal data types in R are numeric, character, factor and logical. There are others, but these are the main ones.\n\nA datum of type numeric is a numerical value, such as a soil pH value.\nA datum of type character is a string of characters, such as the name of an experiment.\nA datum of type factor is the label for a set of treatments or categories which we might use in an analysis of variance.\n\nA datum of type logical takes values TRUE or FALSE"
  },
  {
    "objectID": "data_types.html#numeric-data",
    "href": "data_types.html#numeric-data",
    "title": "2  Data Types",
    "section": "Numeric data",
    "text": "Numeric data\n\nScalar:\nBefore going into details of data types, we introduce the simplest data type in R, the scalar. A scalar is a single value of some variable, e.g. the value 42, or the name \"Bert\".\nWe can make a simple scalar value using the <- “assign” arrow in R. Assignment is simply the association of a name (mass) with an object (the value 1000).\n\nmass<-1000\n\nThis is a numeric scalar value. We can then use the print command to see the value of the scalar\n\nprint(mass)\n\n[1] 1000\n\n\nWe can then do simple mathematical manipulations with a numeric scalar value. For example, the following will convert the mass, if this is in grams, to kg\n\nmass_kg <- mass/1000\n\nso you can see that the back-slash / denotes division of the value to the left by the value to the right. As in most computer languages * denotes multiply, so to convert mass to milligrams we would do the following\n\nmass_mg<-mass*1000\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate a scalar value which is your age at last birthday then, assuming that there are 52 weeks in each year, calculate your age in weeks and assign this value to a scalar called my_age\n\n\nHere are some simple operations which we can perform on a numeric scalar in R using inbuilt functions\n\n\nSquare root\n\nsroot_mass<-sqrt(mass)\n\n\n\nLogarithm (natural or Napierian logarithm to base e)\n\nlog_mass<-log(mass)\n\n\n\nRaising to a power\n\nmass_squared<-mass^2\n\n\n\n\n\n\n\nError Alert:\n\n\n\nRun the commands below with one parenthesis removed and see what happens\n\nsroot_mass<-sqrt(mass\n\n\n\n\n\n\n\n\n\nExercise: Operator precedence\n\n\n\n\nYou may recall from school that, when faced with a string of operations, e.g you do the operations in a certain order, completing calculations inside brackets first. R follows a standard order of precedence in operations. Using the rules from school work out the correct answer to the expression above, and then assign its value in R to a new numeric scalar, and see if you were correct.\n\n\n10-4*(2+1)\n\n[1] -2\n\n\n\nWork out the order of precedence in R for ^,-, +, * by examining the values assigned to numeric scalars by the following\n\n\n1+2*3\n\n[1] 7\n\n3*2^2\n\n[1] 12\n\n3*2^3-1\n\n[1] 23"
  },
  {
    "objectID": "data_types.html#character-data",
    "href": "data_types.html#character-data",
    "title": "2  Data Types",
    "section": "Character data",
    "text": "Character data\nA character scalar is just a string of characters, for example, the name of a treatment\n\ntname<-\"Mulched\"\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the character string in the assignment is put inside double quotes. See what happens if you run the command above, but with the quotes removed.\n\n\nIt can be useful to use character scalars, as they can appear in commands such as those for data plots, and you can assign the value once, so, for example, the following commands would create a pane of three graphs based on two variables, (here on some random data). In each plot command (\"plot\" and \"hist\") \"xlab= \" specifies the name on the x-axis label, and similarly \"ylab=\" for the y-axis. One can put the label name in directly here, xlab=\"pH\", for example, but we can also put a character scalar here which has been given a value elswhere e.g.:\n\n#Assign variable names\nxname<-\"pH\"\nyname<-\"SOC\"\n#Create a pane of four plots\npar(mfrow=c(2,2))\n#Create some random data\nx<-runif(100,4,8)\ny<-rnorm(100,4,0.5)\n#Create the plots\nhist(x,xlab=xname,main=\"Histogram\")\nhist(y,xlab=yname,main=\"Histogram\")\nplot(x,y,xlab=xname,ylab=yname,pch=16,main=\"Scatterplot\")\n# Reset the plot window\npar(mfrow=c(1,1))\n\n\n\n\nIf you were using the script to produce such plots from various variables you can see how using a character scalar saves you from having to type the same variable name into the function for each plot. Changing it once at the top ensures that you get the correct name in each case.\nUsing \"paste\" to combine character variables.\nImagine that I had a character scalar that denotes the block to which an experimental plot belongs in a RCBD experiment, and another one that denotes the treatment:\n\nblock<-\"Block1\"\ntreatment<-\"CA\"\n\nI can make a plot name by combining these two using paste. The \"sep\" term allows me to specify the separator between the two scalars:\n\nplot_lab<-paste(block,treatment,sep=\"_\")\nprint(plot_lab)\n\n[1] \"Block1_CA\"\n\n\n\n\n\n\n\n\nEXERCISE (by yourself)\n\n\n\nCreate a character scalar that includes your name and then use paste to join thiswith your age in weeks(as computed in the section on numeric data types)."
  },
  {
    "objectID": "data_types.html#logical-data",
    "href": "data_types.html#logical-data",
    "title": "2  Data Types",
    "section": "Logical data",
    "text": "Logical data\nA logical scalar takes the value TRUE or FALSE. An R command which states some relation between two variables will have a logical value. For example, let us create two numeric scalars\n\nthree<-3\nfive<-5\n\nNow the R statement (three < five) will take the value TRUE, because the value of \"three\" is less than the value of \"five\", so\n\nthree_lt_five<-(three < five)\nprint(three_lt_five)\n\n[1] TRUE\n\n\nthe command below will show that it is not the case that three<three\n\nthree_lt_three<-(three < three)\nprint(three_lt_three)\n\n[1] FALSE\n\n\nbut <= (less than or equal to) gives us a different outcome\n\nthree_le_three<-(three <= three)\nprint(three_le_three)\n\n[1] TRUE\n\n\nSome other useful “logical connectives” are == for \"equal to\" and != for \"not equal to\" and, of course, > for \"greater than\" and >= for “greater than or equal to”.\n\n\n\n\n\n\nWarning\n\n\n\nNote that == is used for \"equal to\", a single = will allocate the value of the scalar on the left to that on the right.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSatisfy yourself that the set of connectives described above behave as they do, using the scalars three and five above, and others of your creation.\n\n\nLogical variables can be the subject of logical functions, notably \"if .. then\" Consider the example below\n\nsoil_pH <- 4\n\nif(soil_pH < 5.5) {\n    management_option <- \"Lime\"\n    }else{\n        management_option<-\"No_lime\"\n        }\n\nIn the script above if soil_pH is less than 5.5 then the scalar management_option will be given the character value \"Lime\", otherwise it will be given the value \"No_lime\".\n\ntime <- 12.00\nif(time < 12) {\n    learning <- \"continue\" \n    }else{\n        learning_option <- \"take a break\"\n        }\n\nIn the script above if time is less than 12.00 then the scalar learning option will be given the character value \"continue\", otherwise it will be given the value \"take a break\".\nA logical variable can be defined on the basis of more than one logical condition, this can be done using the conditionals & for \"and\", | for \"or\" .&& and || are sometimes appliedto vectors of logical variables. Here is an example. We define three numeric scalars sand, silt and clay as the percent by mass of sand, silt and clay-sized particles in soil.\n\nsand <- 10\nsilt <- 20\nclay <- 70\n\nfirst, check that the values are consistent\n\nconsistent_particle_size <- ((sand + silt + clay) == 100)\nprint(consistent_particle_size)\n\n[1] TRUE\n\n\nThe USDA soil texture class Clay contains soils with more than 40% clay AND less than 40% silt and less than 45% sand, so we can determine whether or not our soil belongs to class clay as follows\n\nis_clay <- (clay>40) | (silt<=40) | (sand<=45)\nprint(is_clay)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\ntry the commands out with some different (consistent) particle size values.\nmodify the commands above so as to compute a logical variable is_silty_clay. In the USDA texture triangle a soil is silty clay if the clay content is greater than 40% AND the silt content is greater than 40%:"
  },
  {
    "objectID": "intro.html#software-requirements",
    "href": "intro.html#software-requirements",
    "title": "1  Introduction",
    "section": "Software requirements",
    "text": "Software requirements\nFirst, we will cover R, which is a powerful and versatile programming language that is widely used for data analysis, statistical modeling, and data visualization.\n\nIt is an open-source software that can be freely downloaded and used by anyone. R is widely used in academia, industry, and government, and is becoming increasingly popular among data scientists and analysts.\nIt is a great tool for those who have been using other statistics tools like Excel, SAS, SPSS and want to take their data analysis skills to the next level.\n\nThis training will provide an introduction to the basics of R and will give you the skills you need to start working with data in R..\nNext, we will introduce RStudio, which is a popular integrated development environment (IDE) for R.\n\nRStudio provides a user-friendly interface for working with R and makes it easy to work with R packages, which are collections of pre-written R code that can be used to perform specific tasks.\nWith RStudio, you will be able to write, test, and debug your R code, and easily share your work with others.\n\n\n\n\nsource: https://moderndive.netlify.app/1-getting-started.html\n\n\nThis manual will provide step-by-step instructions for installing and setting up R and RStudio on your computer. We will also go over basic concepts and commands for working with each technology, as well as provide examples of how to use them in different contexts. With this manual, you will have the skills and knowledge you need to start using these powerful technologies to better understand your data and collaborate with others on your project."
  },
  {
    "objectID": "data_structures.html#vectors",
    "href": "data_structures.html#vectors",
    "title": "3  Data Structures",
    "section": "Vectors",
    "text": "Vectors\nA vector is a series of values of a variable (e.g. pH value measurements from a sensor). The easiest way to form a vector of values in R is with the \"combine\" function c(). An example of a vector of numeric values (pH readings) is shown below:\n\npH_values <- c(5.6, 5.5, 5.0, 5.7, 5.4, 5.3, 6.0, 6.7, 6.5, 6.4, 6.2, 6.3)\n\nWe can count the number of items in a vector with the length() function:\n\nlength(pH_values)\n\n[1] 12\n\n\nEach item in a vector can be referenced by its index (i.e. its position in the sequence of values), and we can pull out a particular item using the square brackets after the vector name. For example, the 7th item in pH_values can be accessed like this\n\npH_values[7]\n\n[1] 6\n\n\nA vector is a “homogeneous” data structure. You could make a vector of logical values or of numeric values or of character values, but not a vector which has a mixture.\nSee what happens if you try:\n\nmixture <- c(5.2, TRUE, \"CA\")\nprint(mixture)\n\n[1] \"5.2\"  \"TRUE\" \"CA\"  \n\n\neverything is turned into a character, and so appears in quotation marks. You could not perform arithmetic on the first object in the vector, as you can see if you try:\n\nsqrt(mixture[1])\n\nThe operations that we have applied above to scalar data types can be applied to vectors. So, for example, see what happens with the R command\n\nprint(2*pH_values)\n\n [1] 11.2 11.0 10.0 11.4 10.8 10.6 12.0 13.4 13.0 12.8 12.4 12.6\n\n\nthe operation is applied to every element in the vector, and the output is a vector.\nThere are other functions that we can apply to vectors for example\n\nmean_pH <- mean(pH_values) \nprint(mean_pH)\n\n[1] 5.883333\n\n\n\n\n\n\n\n\nExcercise\n\n\n\nExplore what the functions sum() and median() do using the pH_values vector\n\n\nA conditional operation applied to a vector will produce a vector of logical values\n\npH_le_6 <- pH_values <= 6.0\nprint(pH_le_6)\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\n\nThe which() function, applied to a vector, will extract the index values for all values in the vector which meet certain conditions, e.g.:\n\nindex_lt_6 <- which(pH_values<6)\nprint(index_lt_6)\n\n[1] 1 2 3 4 5 6\n\n\nwe can use this vector of index values to extract the pH values which meet the condition into a new vector:\n\nsmall_pH_values <- pH_values[index_lt_6]\nprint(small_pH_values)\n\n[1] 5.6 5.5 5.0 5.7 5.4 5.3\n\n\n\n\n\n\n\n\nExercise\n\n\n\nExtract into a new vector the values of pH which exceed 5.6\n\n\nIf we use the multiplication operation on two vectors, a and b, which are the same length…\n\na<-c(1,2,3,4,5)\n\nb<-c(1,10,100,1000,10000)\n\nc<-a*b\n\nprint(c)\n\n[1]     1    20   300  4000 50000\n\n\n… then the output, c, is a vector of the same length as a or b, where c[i]= a[i]*b[i]. If a and b were of different length you would get an error message.\n\n\n\n\n\n\nTip\n\n\n\nNote that this is not a standard product of vectors from matrix algebra.\n\n\nThere are various useful commands for creating vectors, rep() is one of the best.A assume that our pH values are drawn from six soil samples which are sands (S) and six which are clay loam (CL). We can make a vector of character values which corresponds to the pH data with the following command:\n\nsoil_type <- rep(c(\"S\",\"CL\"),each=6)\n\nprint(soil_type)\n\n [1] \"S\"  \"S\"  \"S\"  \"S\"  \"S\"  \"S\"  \"CL\" \"CL\" \"CL\" \"CL\" \"CL\" \"CL\"\n\n\nand you could then extract the index of the clay loams:\n\nclay_loam_index <- which(soil_type==\"CL\")\n\n… and then extract the pH values for the clay loam soils\n\npH_clay_loam <- pH_values[clay_loam_index]\n\n\n\n\n\n\n\nExercise\n\n\n\nCompare the output of the rep commands below, in order to work out what \"times\"and \"each\" are doing\n\nrep(c(\"CA\",\"Conv\"),times=6)\n\n [1] \"CA\"   \"Conv\" \"CA\"   \"Conv\" \"CA\"   \"Conv\" \"CA\"   \"Conv\" \"CA\"   \"Conv\"\n[11] \"CA\"   \"Conv\"\n\nrep(c(\"CA\",\"Conv\"),each=6)\n\n [1] \"CA\"   \"CA\"   \"CA\"   \"CA\"   \"CA\"   \"CA\"   \"Conv\" \"Conv\" \"Conv\" \"Conv\"\n[11] \"Conv\" \"Conv\"\n\nrep(c(\"CA\",\"Conv\"),each=2,times=3)\n\n [1] \"CA\"   \"CA\"   \"Conv\" \"Conv\" \"CA\"   \"CA\"   \"Conv\" \"Conv\" \"CA\"   \"CA\"  \n[11] \"Conv\" \"Conv\"\n\nrep(c(\"CA\",\"Conv\"),times=1:2)\n\n[1] \"CA\"   \"Conv\" \"Conv\"\n\n\nUse rep to produce a vector of treatment labels for an experiment in which conservation agriculture (CA) and conventional (Conv) treatments are applied, with six reps of each in 6 blocks. Produce a corresponding vector of block labels."
  },
  {
    "objectID": "data_structures.html#factors",
    "href": "data_structures.html#factors",
    "title": "3  Data Structures",
    "section": "Factors",
    "text": "Factors\nIn the previous section we introduced the idea of vectors of character variables as treatment labels. However, in order to be most useful, such a vector needs to be turned into a factor. A factor is a variable which is not a continuous number, or is not treated as one. It is a label for some variable controlled at different levels in an experiment, so a factor might be Nitrogen (application rate) with levels 0, 50 and 100 kg/ha, or it might be Variety with levels AB_123, AB_234, CD_120, CD_130. When we first set up a vector of N rates these could be numeric, the Varieties will be made character variables because they contain letters. In both cases, however, we are likely to want the variable to be turned into a factor for use in an analysis of variance, for example.The example below sets up two vectors with levels for these factors in an experiment with the two factors in factorial combination (giving 12 treatments) and with four replicates of each treatment in randomized blocks\n\nNitrogen <- rep(c(0,50,100),16)\nVariety <- rep(c(\"AB_123\", \"AB_234\", \"CD_120\", \"CD_130\"),each=3,times=4)\nBlocks <- rep(c(\"Block_1\",\"Block_2\",\"Block_3\",\"Block_4\"),each=12)\n\nThe cbind command below will print out these vectors as columns in a matrix of character values it is easy to see how the twelve combinations of the two factor levels are structured in each block\n\ncbind(Blocks,Variety,Nitrogen)\n\n      Blocks    Variety  Nitrogen\n [1,] \"Block_1\" \"AB_123\" \"0\"     \n [2,] \"Block_1\" \"AB_123\" \"50\"    \n [3,] \"Block_1\" \"AB_123\" \"100\"   \n [4,] \"Block_1\" \"AB_234\" \"0\"     \n [5,] \"Block_1\" \"AB_234\" \"50\"    \n [6,] \"Block_1\" \"AB_234\" \"100\"   \n [7,] \"Block_1\" \"CD_120\" \"0\"     \n [8,] \"Block_1\" \"CD_120\" \"50\"    \n [9,] \"Block_1\" \"CD_120\" \"100\"   \n[10,] \"Block_1\" \"CD_130\" \"0\"     \n[11,] \"Block_1\" \"CD_130\" \"50\"    \n[12,] \"Block_1\" \"CD_130\" \"100\"   \n[13,] \"Block_2\" \"AB_123\" \"0\"     \n[14,] \"Block_2\" \"AB_123\" \"50\"    \n[15,] \"Block_2\" \"AB_123\" \"100\"   \n[16,] \"Block_2\" \"AB_234\" \"0\"     \n[17,] \"Block_2\" \"AB_234\" \"50\"    \n[18,] \"Block_2\" \"AB_234\" \"100\"   \n[19,] \"Block_2\" \"CD_120\" \"0\"     \n[20,] \"Block_2\" \"CD_120\" \"50\"    \n[21,] \"Block_2\" \"CD_120\" \"100\"   \n[22,] \"Block_2\" \"CD_130\" \"0\"     \n[23,] \"Block_2\" \"CD_130\" \"50\"    \n[24,] \"Block_2\" \"CD_130\" \"100\"   \n[25,] \"Block_3\" \"AB_123\" \"0\"     \n[26,] \"Block_3\" \"AB_123\" \"50\"    \n[27,] \"Block_3\" \"AB_123\" \"100\"   \n[28,] \"Block_3\" \"AB_234\" \"0\"     \n[29,] \"Block_3\" \"AB_234\" \"50\"    \n[30,] \"Block_3\" \"AB_234\" \"100\"   \n[31,] \"Block_3\" \"CD_120\" \"0\"     \n[32,] \"Block_3\" \"CD_120\" \"50\"    \n[33,] \"Block_3\" \"CD_120\" \"100\"   \n[34,] \"Block_3\" \"CD_130\" \"0\"     \n[35,] \"Block_3\" \"CD_130\" \"50\"    \n[36,] \"Block_3\" \"CD_130\" \"100\"   \n[37,] \"Block_4\" \"AB_123\" \"0\"     \n[38,] \"Block_4\" \"AB_123\" \"50\"    \n[39,] \"Block_4\" \"AB_123\" \"100\"   \n[40,] \"Block_4\" \"AB_234\" \"0\"     \n[41,] \"Block_4\" \"AB_234\" \"50\"    \n[42,] \"Block_4\" \"AB_234\" \"100\"   \n[43,] \"Block_4\" \"CD_120\" \"0\"     \n[44,] \"Block_4\" \"CD_120\" \"50\"    \n[45,] \"Block_4\" \"CD_120\" \"100\"   \n[46,] \"Block_4\" \"CD_130\" \"0\"     \n[47,] \"Block_4\" \"CD_130\" \"50\"    \n[48,] \"Block_4\" \"CD_130\" \"100\"   \n\n\nNow use the factor() function to create factor data structures.\n\nNitrogen_factor<-factor(Nitrogen)\nprint(Nitrogen_factor)\n\nVariety_factor<-factor(Variety)\nprint(Variety_factor)\n\nBlock_factor<-factor(Blocks)\nprint(Block_factor)\n\nNote that a factor is actually a vector, but with an associated list of levels, always presented in alpha-numeric order. These are used by R functions such as lm() which does linear modelling, such as the analysis of variance. We shall see how factors can be used in the later section on data frames.\n\n\n\n\n\n\nExercise\n\n\n\nAn experiment has been set up to examine the combined effects of zero till vs conventional tillage with intercropping vs monocropping. The experiment is designed with randomized complete blocks, each of five blocks contains one replicate of each treatment. Following the example above, set up the three factors required to represent one season of this experiment."
  },
  {
    "objectID": "data_structures.html#matrices",
    "href": "data_structures.html#matrices",
    "title": "3  Data Structures",
    "section": "Matrices",
    "text": "Matrices\nA matrix is a rectangular array of values, arranged in rows and columns. A vector is therefore a type of matrix with just one column. We can create a matrix in R in one of two main ways. The first is the matrix command:\n\nM1 <- matrix(1:6,3,2)\nprint(M1)\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\nThe first term in the command is a vector of numbers, 1 to 6, the second is the number rows in the matrix and the third is the number of columns. Note that we always refer to an entry in the matrix by the ROW first and the COLUMN second. As an exercise, look at the effect of swapping 3 and 2 round in the command above. Note also that the command enters the terms down the first column then down the second, so that the first column of M1 goes 1,2,3 and the second 4, 5, 6.\nThe second way to make a matrix in R is to \"bind\" some vectors together, which works only if they are the same length. If we start with 2 vectors:\n\na <- c(2,4,5)\nb <- c(4,7,10)\n\n.. then we can make a 3 x 2 matrix (remember that means 3 rows and 2 columns) with the cbind() command (for binding the vectors as columns of the matrix):\n\nM2 <- cbind(a,b)\nprint(M2) \n\n     a  b\n[1,] 2  4\n[2,] 4  7\n[3,] 5 10\n\n\n… and we could make a 2 x 3 matrix with the rbind() command (for binding the vectors as rows of the matrix):\n\nM3 <- rbind(a,b)\nprint(M3) \n\n  [,1] [,2] [,3]\na    2    4    5\nb    4    7   10\n\n\nNote that the vector names become column or row names of the matrix. You can look at these names with the colnames or rownames command, and also use these to change the names:\n\ncolnames(M2)\n\n[1] \"a\" \"b\"\n\ncolnames(M2) <- c(\"Column_1\",\"Column_2\")\n\ncolnames(M2)\n\n[1] \"Column_1\" \"Column_2\"\n\n\nWe can refer to a particular cell of a matrix as follows\n\nM2[2,2]\n\nColumn_2 \n       7 \n\n\n.. and we can refer to a particular column of the matrix as follows\n\nM2[,2]\n\n[1]  4  7 10\n\n\nFor example, to find the sum of the first column of M2 ..\n\nSum_Col_1 <- sum(M2[,1])\n\nprint(Sum_Col_1)\n\n[1] 11\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTake the vectors below (from an exercise above) which contain gravimetric water content and bulk density of ten soils. Combine these two as columns in a matrix and then change the column names to \"Gravimetric_water\" and \"Bulk_density\".\n\ngwc <- c(0.4,0.5,0.3,0.2,0.5,0.6,0.3,0.2,0.4,0.3)\nrho <- c(1.05,1.42,1.50,1.65,1.44,0.90,1.35,1.36,1.10,1.43)\ngr <- cbind(gwc,rho)\n\ncolnames(gr)<-c(\"Gravimetric_water\",\"Bulk_density\")\n\nWhen that is done, extract the mean value of bulk density from the matrix."
  },
  {
    "objectID": "data_structures.html#data-frames",
    "href": "data_structures.html#data-frames",
    "title": "3  Data Structures",
    "section": "Data frames",
    "text": "Data frames\nA matrix or a vector is a “homogeneous” data structure, which means you can’t mix data types. Consider the previous example, we have a vector of numeric data on soil pH:\n\npH_values<-c(5.6, 5.5, 5.0, 5.7, 5.4, 5.3, 6.0, 6.7, 6.5, 6.4, 6.2, 6.3)\n\n… and a corresponding vector of character values on the soil texture class for each sample\n\nsoil_type<-rep(c(\"S\",\"CL\"),each=6)\n\n.. and then attempt to put the character and the numeric vector into a matrix:\n\ncombined_data<-cbind(soil_type,pH_values)\n# print the outcome..\nprint(combined_data)\n\n      soil_type pH_values\n [1,] \"S\"       \"5.6\"    \n [2,] \"S\"       \"5.5\"    \n [3,] \"S\"       \"5\"      \n [4,] \"S\"       \"5.7\"    \n [5,] \"S\"       \"5.4\"    \n [6,] \"S\"       \"5.3\"    \n [7,] \"CL\"      \"6\"      \n [8,] \"CL\"      \"6.7\"    \n [9,] \"CL\"      \"6.5\"    \n[10,] \"CL\"      \"6.4\"    \n[11,] \"CL\"      \"6.2\"    \n[12,] \"CL\"      \"6.3\"    \n\n\nWe can can see that the pH values are now character, a string \"5.6\" which could not be used in calculations.\nLet us see what happens if we convert soil type to a factor first..\n\nsoil_type <- factor(soil_type)\ncombined_data <- cbind(soil_type,pH_values)\n\n#print the outcome..\nprint(combined_data)\n\n      soil_type pH_values\n [1,]         2       5.6\n [2,]         2       5.5\n [3,]         2       5.0\n [4,]         2       5.7\n [5,]         2       5.4\n [6,]         2       5.3\n [7,]         1       6.0\n [8,]         1       6.7\n [9,]         1       6.5\n[10,]         1       6.4\n[11,]         1       6.2\n[12,]         1       6.3\n\n\n… the factor values have been converted to numeric ones (label 1 goes to the factor whose original name came first in alphabetical order (“CL”).\nThis is why matrices, while important for many applications, are not the most basic data structure in R. The data frame serves this purpose, which is why we will generally use commands such as read.table or read.csv to read data from external files into an R data frame\nWe can turn our two vectors into a data frame as follows:\n\ncombined.df <- data.frame(\n    soil_type=soil_type,\n    pH_values=pH_values,\n    stringsAsFactors = TRUE\n    )\n\nThe option \"stringsAsFactors = TRUE\" tells R that soil_type should be treated as a factor.\nWe can reference the data object inside the data frame using the dollar notation, combined.df$soil_type so we can confirm that soil_type is indeed a factor in the data frame as follows.\n\nprint(combined.df$soil_type)\n\n [1] S  S  S  S  S  S  CL CL CL CL CL CL\nLevels: CL S\n\n\nWe now have a data frame in which the soil_type variable is a factor and the pH_values are numeric: just what we need.\n\nprint(combined.df)\n\n   soil_type pH_values\n1          S       5.6\n2          S       5.5\n3          S       5.0\n4          S       5.7\n5          S       5.4\n6          S       5.3\n7         CL       6.0\n8         CL       6.7\n9         CL       6.5\n10        CL       6.4\n11        CL       6.2\n12        CL       6.3\n\n\nThis allows us to do some interesting things. For example, make a boxplot of pH within each level of the factor\n\nboxplot(pH_values~soil_type,data=combined.df)\n\n\n\n\n… or to extract the mean value of pH for each level of the factor\n\nby(combined.df$pH_values,combined.df$soil_type,mean)\n\ncombined.df$soil_type: CL\n[1] 6.35\n------------------------------------------------------------ \ncombined.df$soil_type: S\n[1] 5.416667\n\n\n… or to do a t-test to compare the mean pH values\n\nt.test(pH_values~soil_type,data=combined.df)\n\n\n    Welch Two Sample t-test\n\ndata:  pH_values by soil_type\nt = 6.5814, df = 9.9951, p-value = 6.236e-05\nalternative hypothesis: true difference in means between group CL and group S is not equal to 0\n95 percent confidence interval:\n 0.6173319 1.2493348\nsample estimates:\nmean in group CL  mean in group S \n        6.350000         5.416667 \n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the terms in brackets for t.test and boxplot are identical. They are: a) formula saying express the first variable in terms of different levels of the factor and a) a data statement pointing R to the data frame where it will find the variables with the specified names.\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nFind the mean of all the pH values in combined.df\nFind the median values of pH in the two textural classes\n\n\n\nThree useful R commands, which can be applied to data frames and are particularly useful when examining one created by reading in data are names(), head() and nrow(). Apply these to combined.df in order to work out what they do.\n\nnames(combined.df)\n\n[1] \"soil_type\" \"pH_values\"\n\nhead(combined.df)\n\n  soil_type pH_values\n1         S       5.6\n2         S       5.5\n3         S       5.0\n4         S       5.7\n5         S       5.4\n6         S       5.3\n\nnrow(combined.df)\n\n[1] 12\n\n\nThe colnames() command can be used either to show or to set the column names (as for matrices)\n\ncolnames(combined.df)\n\n[1] \"soil_type\" \"pH_values\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe two sets of values below are, respectively, the bulk density of 20 different topsoil samples and their textural class: sandy loam (SL) or silt loam (KL).\n\nbulk_density <- c(1.46,1.44,1.43,1.42,0.96,1.3,1.48,1.22,1.41,1.5,1.27,\n1.21,1.23,1.16,1.27,1.37,1.07,1.16,1.04,1.42)\n\n# textural_class <- c(\"SL\",\"SL\",\"SL\",SL,SL,SL,SL,SL,SL,SL,KL,KL,KL,KL,KL,KL,KL,KL,KL,KL)\ntextural_class <- rep(c(\"SL\",\"KL\"),each=10)\n  \ndf <- data.frame(\n    bulk_density=bulk_density,\n    textural_class=textural_class,\n    stringsAsFactors = TRUE\n    )\n\nprint(df)\n\n   bulk_density textural_class\n1          1.46             SL\n2          1.44             SL\n3          1.43             SL\n4          1.42             SL\n5          0.96             SL\n6          1.30             SL\n7          1.48             SL\n8          1.22             SL\n9          1.41             SL\n10         1.50             SL\n11         1.27             KL\n12         1.21             KL\n13         1.23             KL\n14         1.16             KL\n15         1.27             KL\n16         1.37             KL\n17         1.07             KL\n18         1.16             KL\n19         1.04             KL\n20         1.42             KL\n\n\nMake a data frame in which textural class is a factor and bulk density is a numerical variable Give each column an appropriate name then: i) produce a boxplot of bulk density in the twotexture classes i) compute the mean bulk density over all the data and i) compute the mean bulk density for each textural class separately then i) conduct a t-test to compare the two textural classes with respect to bulk density."
  },
  {
    "objectID": "data_structures.html#lists",
    "href": "data_structures.html#lists",
    "title": "3  Data Structures",
    "section": "Lists",
    "text": "Lists\nA list in R is a vector of data objects. It can be a useful structure for holding outputs from analyses in a consistent format, and you might find that some packages you use produce lists as outputs.\nIn this example we take three vectors of values and put them together in a list:\n\nlist_example <- list(\"some_numbers\"=c(1,2,3,4), \n\"some_odd_numbers\"=c(1,3,5,7), \n\"some_even_numbers\"=c(2,4,6,8))\n\nprint(list_example)\n\n$some_numbers\n[1] 1 2 3 4\n\n$some_odd_numbers\n[1] 1 3 5 7\n\n$some_even_numbers\n[1] 2 4 6 8\n\n\nThe three components of the list are referred to as list “slices” You can use the name of a slice and the dollar notation to refer to a particular slice\n\nlist_example$some_even_numbers\n\n[1] 2 4 6 8\n\n\nand because a slice is a vector you can refer to a single element of it by its index (order in the vector) and the square brackets notation:\n\nlist_example$some_even_numbers[3]\n\n[1] 6\n\n\nAlternatively, you can refer to slices of a list by using the double square bracket with an index (for the first, second… slice). For example, an alternative way to reference the vector \"some_even_numbers\", which is the third slice, is as follows\n\nlist_example[[3]]\n\n[1] 2 4 6 8\n\n\n.. and you can refer to an element of this vector thus\n\nlist_example[[3]][4]\n\n[1] 8\n\n\nFor example, one may change the value of the fourth element in the third slice as follows\n\nlist_example[[3]][4]<-10\n\n\n\n\n\n\n\nHome Exercise\n\n\n\nProduce a list object based on the data in the last exercise which contains the following slices.\n\nall the bulk density data\n\nthe list of corresponding textural classes\nthe mean bulk density over all the data and\nthe mean bulk densities for the two classes."
  },
  {
    "objectID": "reading_data.html#introduction",
    "href": "reading_data.html#introduction",
    "title": "4  Reading/Importing Data",
    "section": "Introduction",
    "text": "Introduction\nThe objective of this section is to provide information on the topic under consideration, along with examples and exercises. You should be able to work through it in R or R studio.\nThis section is concerned with how we get numbers into R, and then write numbers out again. By the end you should have a better understanding of the R scripts, and should be better-placed to start developing and editing scripts yourself. The particular topics we shall cover are:\n\nReading simple data files into R\nWriting data out of R\nReading data from Excel files\n\nIn most applications of R we need to start by reading in data from a file which has been created elsewhere, perhaps using an editor, a spreadsheet or as output from a particular piece of equipment or software. In this script we explore some options for doing this."
  },
  {
    "objectID": "reading_data.html#setting-the-working-directory",
    "href": "reading_data.html#setting-the-working-directory",
    "title": "4  Reading/Importing Data",
    "section": "Setting the working directory",
    "text": "Setting the working directory\nBefore you read data into R, you must ensure that R knows where to look for the data on your computer. It is possible to give a full path to the file, but is usually most convenient to set the folder with the data as the working directory. This can be done using the \"Change directory..\" option from the \"Session\" drop down menu when the R console is active. Or from the \"File browser\" three dots ... (click to navigate to folder), and then \"More\" icon drop down to set working directory Alternatively you can use the \"setwd\" (set working directory) command as follows:\nThree ways of setting a working directory:\n\nsetwd: you need to know the working directory path, which I find complicated\n\n\nsetwd(\"C:/Users/sbzhp/OneDrive - The University of Nottingham/Documents/Basic R and Summary Statistics/Intro_to_R/Tanz_Training\")\n\n\nUse the Session tool on the Tool bar: Session etc.\nUse the File Browser of RStudio:\n\n\nNavigate to the folder you want to set as working directory\nThen \"click\" on the \"More\" tab (has a cog/wheel next to it)\nThen \"Click\" on \"Set as Working Directory\"\n\nYou can derive the full path to the file/working directory using \"getwd\" function:\n\ngetwd()\n\n\n\n\n\n\n\nTip\n\n\n\nNote that this is a path to the directory on my computer. Edit it to give the correct path to the directory where you are working. Also note that R uses forward slashes, /, in directory paths rather than the more common backslash."
  },
  {
    "objectID": "reading_data.html#reading-simple-data-files-into-r",
    "href": "reading_data.html#reading-simple-data-files-into-r",
    "title": "4  Reading/Importing Data",
    "section": "Reading simple data files into R",
    "text": "Reading simple data files into R\nThe read.table function is one of the most commonly used functions for reading data. It can be used for reading data in simple ascii formats suchas .txt files, or .dat files produced by many applications. If you want to read in data from a .csv file (comma-separated values), as is commonly output from an Excel spreadsheet, then you can use the variant read.csv command.\nread.table or read.csv assume that the data are organized in columns in the file, one column for each variable, and one row corresponds to a single observation (e.g. an experimental plot or a soil core) for which we may have several factor labels, and several variables measured.\nread.table or read.csv has a few important arguments:\n\nfile: the name of the file which you want to read. At its simplest this is just a file name, in double quotes, (\"data.dat\", for example), when this file is present in the working directory but there are more complex options.\n\n\n# See ?read.table for details\n?read.table\n\n\nheader: this is a logical argument so it takes value T (true) if the firstrow of the file is a header with names of the variables in columns, and F otherwise.\n\nThese two arguments are often all that you will need, for small files. There are some other useful ones, for example:\n\nskip: the number of lines to skip from the beginning (e.g if you don’t want to look at the first 100 lines of the file.\nstringsAsFactors: should character variables be coded as factors? This will ensure that R treats any variables which have letters in them (e.g. “A1”) as factors (i.e. labels for levels of a categorical variable such as variety or cultivation method). Recent releases of R do not do this by default, so this argument can be very useful. If you wanted all character variables to be treated as factors then include stringsAsFactors=T in the command.\n\nWe use read.table to create a data frame from the contents of a file Variety_yileds.txt.\n\ndata.df<-read.delim(\"data/Variety_yields.csv\",header=T,stringsAsFactors=T)\nhead(data.df)\n\n       Variety.Yield\n1 A,8.74767016670302\n2 A,15.6372430831258\n3 A,7.92219914616877\n4 A,8.93414573128023\n5 A,5.67850644886995\n6 A,8.09689378414148\n\n\nWe use read.table to create a data frame from the contents of a file Cashmore_soil.dat.\n\ndata.df <- read.table(\"data/Cashmore_soil.dat\",header=T,stringsAsFactors=T)\nhead(data.df)\n\n  GWC_T GWC_S pH_T pH_S OM_T OM_S Soil_Series\n1  21.4  16.4 7.27 6.66 2.42 0.22          Lw\n2  23.0  25.5 6.35 6.26 2.20 0.54          Lw\n3  22.9  23.7 6.22 6.36 2.54 0.55          Lw\n4  20.8  17.0 6.50 6.65 4.48 2.53          Lw\n5  20.0  18.6 6.57 6.48 4.26 1.89          Lw\n6  20.8  16.7 6.26 6.50 3.47 2.45          Lw\n\n\n\n\n\n\n\n\nTip\n\n\n\nMake sure that the file name in the editor matches the file name in the directory!!\n\n\nWe use read.csv to create a data frame from the contents of a file yielddata.csv.\n\ndata.df <- read.csv(\"data/yielddata.csv\",header=T,stringsAsFactors=T)\nhead(data.df)\n\nThe data frame is now ready for use. It can be helpful to examine the data frame with various R tools before proceeding to any analyses. For example,\n\nstr(data.df) \n\nstr function describes the structure of the data frame. It tells you the number of rows (observations) in the data.frame and the number of columns (variables) that it contains. It also tells you the kind of data each variable comprises (recall that a data frame can contain different data structures).\nThis example data frame contains data from a field experiment It was a Split-split design carried out in 2016/2017 season, with pd (planting date) as main plot; variety (maize) as sub plot; nrate (nitrogen fertilizer rate) as sub-sub plot; x_100_grain_wt (100 seed grain weight)\nThe following commands can also be useful:\n\nnames(data.df)      # displays the names of the variables in the dataframe\nhead(data.df)       # displays the first 6 rows of the dataframe\ntail(data.df)       # displays last 6 rows of the dataframe\nhead(data.df,10)    # displays 10 rows of the dataframe\nnrow(data.df)       # displays the number of rows\nncol(data.df)       # displays number of columns\n\nWhen you are happy with the content and structure of the data frame, then you can access variables from within it with R commands. A very simple way to access a variable in a dataframe is by the “dollar notation” i.e. $, given the name of the variable.\nFor example, to produce a set of summary plots of the 100-grain weights in the data frame created above, using the \"summaplot\" command from CEPHaStat we do the following:\n\n# load required library\nsource(\"data/custom_functions/CEPHaStat_2.R\")\n\nCEPHaStat version  v1.1 Correction to order of summa output\n\nCEPHaStat is a collection of R functions produced by the UKRI GCRF\nCEPHaS project.  The functions relate primarily to statistical analysis of\nsoil and related data from agricultural and environmental surveys and \nexperiments.  The CEPHaStat file can be shared as it stands, and is made \navailable to all for use, without warranty or liability.\n\nCurrent list of functions\n\nskew kurt ocskew\nsumma summaplot outliers\nokgridvar, sv, dis\nvanG, vanGdraw, campB, campDdraw, plotgroups\n \n\n\n\n\n\n\n\n\nNote: CEPHaStat is a script of functions prepared beforehand.\n\n\n\nThe script is saved in the working directory from where it is “sourced”\n\n\n\nsummaplot(data.df$x_100_grain_wt)\n\nnote that you refer to the vector of data using:\n\nthe name of the dataframe i.e. data.df,\na $ sign and\nthe variable name, with no spaces i.e. x_100_grain_wt\n\nYou can create a new variable within a data frame using the <- assign operator. For example, to create a new variable which is the hundred grain weight in mg, you just multiply the original values (in grams) by 1000\n\ndata.df$x_100_grain_wt_mg <- data.df$x_100_grain_wt*1000\n\nyou can now see that the data frame contains an additional variable\n\nhead(data.df)\n\n  GWC_T GWC_S pH_T pH_S OM_T OM_S Soil_Series\n1  21.4  16.4 7.27 6.66 2.42 0.22          Lw\n2  23.0  25.5 6.35 6.26 2.20 0.54          Lw\n3  22.9  23.7 6.22 6.36 2.54 0.55          Lw\n4  20.8  17.0 6.50 6.65 4.48 2.53          Lw\n5  20.0  18.6 6.57 6.48 4.26 1.89          Lw\n6  20.8  16.7 6.26 6.50 3.47 2.45          Lw"
  },
  {
    "objectID": "reading_data.html#exercise-reading-data-from-a-file",
    "href": "reading_data.html#exercise-reading-data-from-a-file",
    "title": "4  Reading/Importing Data",
    "section": "Exercise : Reading data from a file",
    "text": "Exercise : Reading data from a file\n\n\n\n\n\n\nExercise : Reading data from a file\n\n\n\n\nUse read.csv to read the soil data in the file \"Cashmore_soil.csv\" into an R dataframe, making sure that character variables are read in as factors.\n\nThe variables in the data file are:\n\n\n\n\n\n\n\nVariable name\nDescription\n\n\n\n\nGWC_T GWC_S\ngravimetric water content of the topsoil (_T) and subsoil.\n\n\npH_T pH_S\npH of the topsoil and subsoil\n\n\nOM_T OM_S\norganic matter content of the topsoil and subsoil\n\n\nSoil_Series\nthe soil series (soil class)\n\n\n\n\nExamine the structure of the data set\n\n\nstr( )\n\n\nMake summary plots of the continuous soil variables\nMake a new variable in the data frame which is the log of the gravimetric water content of the subsoil, and make a summary plot of it.\n\n\n\n\n\n\n\nTip\n\n\n\nRecall that the R function \"log\" will return the natural logarithm thus y<-log(x)."
  },
  {
    "objectID": "reading_data.html#exercise-reading-data-from-a-file-2",
    "href": "reading_data.html#exercise-reading-data-from-a-file-2",
    "title": "4  Reading/Importing Data",
    "section": "Exercise : Reading data from a file",
    "text": "Exercise : Reading data from a file\n\n\n\n\n\n\nHomework Exercise : Reading data from a file\n\n\n\nThe data are also provided in an ascii file \"Cashmore_soil.dat\". Use the read.table command to convince yourself that these are the same data!"
  },
  {
    "objectID": "writing_data.html#introduction",
    "href": "writing_data.html#introduction",
    "title": "5  Writing/Exporting Data",
    "section": "Introduction",
    "text": "Introduction\nAfter manipulating data in a data frame we might want to save the output, either to be used with other software, or to save for archiving or further use in R. To produce a .txt file as output you can use the write.table command.\nFirst, we make a new data frame from random variables\n\nVariety <- (rep(c(\"A\",\"B\",\"C\"),each=10))\n# converting varieties to factors\nexample.df <- data.frame(Variety,stringsAsFactors=T)\n# number of obsv, mean, sd\nexample.df$Yield <- rnorm(30,10,5)\n\nhead(example.df)\n\n  Variety     Yield\n1       A 13.677097\n2       A  3.858295\n3       A 16.832529\n4       A  8.614313\n5       A 11.691872\n6       A  4.291216\n\n\nFirst try the following\n\nwrite.table(example.df,\"Variety_yields.txt\")\n\nGo to your working directory and look at the resulting file. The first few lines will be something like this\n\n\n\n\n“Variety”\n“Yield”\n\n\n\n\n“1”\n“A”\n14.9320801147097\n\n\n“2”\n“A”\n13.2040635718118\n\n\n“3”\n“A”\n17.6780697654481\n\n\n“4”\n“A”\n10.3252632315969\n\n\n“5”\n“A”\n7.79996535504178\n\n\n“6”\n“A”\n18.0229009561374\n\n\n“7”\n“A”\n10.2652234419097\n\n\n“8”\n“A”\n4.44808130068076\n\n\n“9”\n“A”\n6.62607203181109\n\n\n“10”\n“A”\n9.59345532285773\n\n\n“11”\n“B”\n13.4659787880458\n\n\n\nThere are some features we might not like, first, the row numbers, which will often be a nuisance when reading the file back into R or other software. Second, the quotation marks around the variable names. We can fix these as follows\n\nwrite.table(example.df,file=\"Variety_yields.txt\",row.names=F,quote=F)\n\nThe first few lines of the file now look like this\n\n\n\nVariety\nYield\n\n\n\n\nA\n14.9320801147097\n\n\nA\n13.2040635718118\n\n\nA\n17.6780697654481\n\n\nA\n10.3252632315969\n\n\nA\n7.79996535504178\n\n\nA\n18.0229009561374\n\n\nA\n10.2652234419097\n\n\nA\n4.44808130068076\n\n\nA\n6.62607203181109\n\n\nA\n9.59345532285773\n\n\nB\n13.4659787880458\n\n\n\nYou can use the write.csv command to make your output a .csv file.\n\nwrite.csv(example.df,file=\"Variety_yields.csv\",row.names=F,quote=F)"
  },
  {
    "objectID": "writing_data.html#overwriting-files",
    "href": "writing_data.html#overwriting-files",
    "title": "5  Writing/Exporting Data",
    "section": "Overwriting files",
    "text": "Overwriting files\nIf you write out a file with the same name as one that is open in the working directory you will get an error message. To try it: Go to your working directory and open the csv file \"Variety_yields\" you have just written Now, rewrite the the file and see what happens\n\nwrite.csv(example.df,file=\"Variety_yields.csv\",row.names=F,quote=F)\n\n\n\n\n\n\n\nExercise: Overwritting files\n\n\n\n\nwrite out a file to the working directory.\n\n\nwrite.csv(example.df,file=\"Variety_yields.csv\",row.names=F,quote=F)\n\n\nDo not open it. Or close it if open.now,\nwrite out another file with the same name to the same working directory How many files of the same name appear in the working directory? Only one because the other has been overwritten :::{.callout-tip} you can use help(\"write.csv\") or ?write.csv to see the options provided by write.csv\n\n\n\n:::"
  },
  {
    "objectID": "writing_data.html#exercise",
    "href": "writing_data.html#exercise",
    "title": "5  Writing/Exporting Data",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nExercise:\n\n\n\nGo back to the data frame you made with the soil data in the file \"Cashmore_soil.csv\".\nThe variables in the data file are: |Variable name |Description| |:—|:—| |GWC_T, GWC_S |gravimetric water content of the topsoil (_T) and subsoil.| |pH_T, pH_S |pH of the topsoil and subsoil| |OM_T, OM_S |organic matter content of the topsoil and subsoil| |Soil_Series |the soil series (soil class)|\n\nadd a variable to the dataframe which is the log of subsoil GWC.\nThen write this supplemented data file to a new .txt format file,\nand to a new .csv file."
  },
  {
    "objectID": "writing_data.html#exercise-2",
    "href": "writing_data.html#exercise-2",
    "title": "5  Writing/Exporting Data",
    "section": "Exercise",
    "text": "Exercise\n:::{.callout-note} ## Homework Exercise : Reading data from Excel files. Homework\nOften your data may be in an Excel file, and it is possible to read data directly from such a file into a data frame. This requires a suitable package. The readxl package is particularly useful and can be used to read .xls or .xlsx . You should install it on your computer using the command install.packages(\"readxl\")\nWhen readxl is installed (package: install.readxl), then you only need to load it in future R sessions, using the command:\n\n# install the package. Uncomment the line below if you need to install the package\n# install.packages(\"readxl\")\n\n# load the package\nlibrary(readxl) \n\n# read the documentation of the package\nhelp(\"readxl\") \n\nThe readxl package makes it easy to get data out of Excel and into R. Compared to many of the existing packages (e.g. gdata, xlsx, xlsReadWrite) readxl has no external dependencies, so it’s easy to install and use on all operating systems. It is designed to work with tabular data.\nYou are provided with an Excel file called soil.xlsx. This contains two sheets. The first contains some data on soil clay content and on soil organic carbon content. The second sheet contains some data on soil pH measured on the same sample in water or in calcium chloride. # The excel_sheets() command in readxl will tell you the names of the sheets in an Excel file available in your working directory:\n\nlibrary(readxl)\n# this shows the sheet names within the \"soil.xlsx\" file\nexcel_sheets(\"data/soil.xlsx\") \n\n[1] \"clay_SOC\" \"pH\"      \n\n\nUsing this information, you can then read a particular sheet from the file into a data frame in R. You can do this either by using the name of the sheet, or the number in the sequence of names:\n\ndata.df <- read_excel(\"data/soil.xlsx\", sheet = \"clay_SOC\")\nhead(data.df)\n\n# A tibble: 6 × 2\n   clay   SOC\n  <dbl> <dbl>\n1     0   0.2\n2    30   0.2\n3    53   0.2\n4     7   0.3\n5     9   0.3\n6    12   0.3\n\n\n… or, equivalently\n\ndata.df<-read_excel(\"data/soil.xlsx\", sheet = 1)\nhead(data.df)\n\n# A tibble: 6 × 2\n   clay   SOC\n  <dbl> <dbl>\n1     0   0.2\n2    30   0.2\n3    53   0.2\n4     7   0.3\n5     9   0.3\n6    12   0.3\n\n\nThe data are now in the dataframe, you can examine its contents, for example, with\n\nstr(data.df)\n\ntibble [141 × 2] (S3: tbl_df/tbl/data.frame)\n $ clay: num [1:141] 0 30 53 7 9 12 4 5 6 13 ...\n $ SOC : num [1:141] 0.2 0.2 0.2 0.3 0.3 0.3 0.4 0.4 0.4 0.4 ...\n\n\nand you can reference the variables using the $ notation, e.g.\n\nplot(data.df$clay,data.df$SOC,xlab=\"Clay content /%\",\nylab=\"Soil organic carbon /%\")\n\n\n\n\nThere are various ways to control which cells are read. See the examples below:\n\nby specifying the maximum number of rows to read in:\n\n\n# this shows the specific number of rows using n_max\ndata.df<-read_excel(\"data/soil.xlsx\", n_max = 3) \nprint(data.df)\n\n# A tibble: 3 × 2\n   clay   SOC\n  <dbl> <dbl>\n1     0   0.2\n2    30   0.2\n3    53   0.2\n\n\n\nby specifying a range in the sheet, using the normal Excel notation (note that row 1 contains the variable names)\n\n\ndata.df<-read_excel(\"data/soil.xlsx\", sheet=1, range = \"A1:B8\")\nprint(data.df)\n\n# A tibble: 7 × 2\n   clay   SOC\n  <dbl> <dbl>\n1     0   0.2\n2    30   0.2\n3    53   0.2\n4     7   0.3\n5     9   0.3\n6    12   0.3\n7     4   0.4\n\n\n\nby specifying a number of rows:\n\n\ndata.df<-read_excel(\"data/soil.xlsx\", sheet=1, range = cell_rows(1:4))\nprint(data.df)\n\n# A tibble: 3 × 2\n   clay   SOC\n  <dbl> <dbl>\n1     0   0.2\n2    30   0.2\n3    53   0.2\n\n\n\nby specifying the cell columns\n\n\ndata.df<-read_excel(\"data/soil.xlsx\", sheet=1,  range = cell_cols(\"A\"))\nprint(data.df)\n\n# A tibble: 141 × 1\n    clay\n   <dbl>\n 1     0\n 2    30\n 3    53\n 4     7\n 5     9\n 6    12\n 7     4\n 8     5\n 9     6\n10    13\n# … with 131 more rows"
  },
  {
    "objectID": "writing_data.html#exercise-3",
    "href": "writing_data.html#exercise-3",
    "title": "5  Writing/Exporting Data",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nHomework Exercise: Reading data from Excel files\n\n\n\n\nUse read.xl functions to read in the first 100 observations on soil pH in soil.xlsx.\n\nThen produce a plot of soil pH measured in water against soil pH measured in calcium chloride.\n\n\n\n\n\n\n\nPossible Solution\n\n\n\n\n\n\nexcel_sheets(\"data/soil.xlsx\")\n\n[1] \"clay_SOC\" \"pH\"      \n\ndata.df<-read_excel(\"data/soil.xlsx\", sheet = \"pH\", range = cell_rows(1:100))\nhead(data.df)\n\n# A tibble: 6 × 2\n    pHw pHCaCl\n  <dbl>  <dbl>\n1   5      4  \n2   5.4    4.4\n3   7.1    6.5\n4   6.3    5.6\n5   7.7    6.8\n6   6.9    6.4\n\nplot(data.df$pHw,data.df$pHCaCl, xlab =\"Ph water\", ylab=\"pHCalc\")"
  },
  {
    "objectID": "writing_data.html#exercise-4",
    "href": "writing_data.html#exercise-4",
    "title": "5  Writing/Exporting Data",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nExcercise : Reading data from Excel files\n\n\n\nYou have been provided with an Excel file called liempe_climatedata.xls\n\nUse the appropriate command from read.xl to list the sheets that it contains\nNext, read the first 360 rows of the monthly weather data into a data frame\nand plot a graph of mean monthly temperature against rainfall."
  },
  {
    "objectID": "functions.html#introduction-to-functions",
    "href": "functions.html#introduction-to-functions",
    "title": "8  Custom Functions",
    "section": "Introduction to functions",
    "text": "Introduction to functions\nFunctions are a fundamental concept in programming and R is no exception. They allow you to encapsulate a set of instructions or an algorithm, which you can then reuse multiple times in your code. In this section, we will learn how to create and use functions in R.\nBefore we start, it’s a good idea to make your code more readable by adding some color to it. In RStudio, you can do this by going to the menu: Tools > Global Options > Code > Display > Rainbow Parentheses (Click apply). This will make it easier to see the start and end of functions.\nIs it looking more colourful now?\n\nstr(list(unique(liempe_data$Month)))\n\n\n\nName\nThe name of a function should be descriptive of what it does. It is good practice to use a verb (a “doing word”) as functions DO things. For example, a function that calculates the median of a dataset could be named \"calculate_median\". Here are some examples of good and bad function names:\n\n\n\n\n\n\nImportant\n\n\n\n\n\n\nGood\nBad\n\n\n\n\nvalidate_data\nvalidation\n\n\ncalculate_likelihood\nlikelihood_calculation\n\n\nmaximise_function\nfunction_maximum\n\n\n\n\n\nIt’s also important to follow a consistent naming convention, such as snake_case or camelCase. You can find more information on this in the Tidyverse style guide: https://style.tidyverse.org/functions.html\n\n\nArguments\nArguments are the input variables that you pass to a function. A function can have no arguments, one argument, or multiple arguments. For example:\nA function with no arguments\n\nfunction() \n\nA function with one argument, i.e. a dataframe, x\n\nfunction(x)\n\nA function with two arguments, i.e. a dataframe, x and a list, y\n\nfunction(x, y)\n\n\n\nFunction Body\nThe function body is the set of instructions or algorithm that you would like your function to execute. It is enclosed in curly braces {}. Here’s a base R example:\n\ncalculate_sum_median <- function(x){\n     y <- sum(x$column1, x$column2)\n     z <- median(y)\n     return (z)\n   }\n\nIn this example, the function takes a dataframe as an argument and calculates the sum of two columns, then calculates the median of the sum.\nHere is an example of how you can re-write the above function using the Tidyverse syntax:\n\nlibrary(tidyverse)\ncalculate_sum_median <- function(x){\n    x %>% \n    select(column1, column2) %>% \n    summarize(sum = sum(column1 + column2)) %>% \n    pull(sum) %>% \n    median()\n}\n\nIn this example, we first load the Tidyverse library, and then define our function calculate_sum_median() , which takes in the dataframe \"x\" as an argument. Inside the function, we use the pipe operator(%>%) to chain together several Tidyverse functions to achieve the same result as the previous example.\nWe first select the columns \"column1\" and \"column2\" using the select() function, then we use the summarize() function to calculate the sum of these two columns and store it in a new variable \"sum\". We then use the pull() function to extract the value of \"sum\" and finally, we use the median() function to calculate the median of this value.\nNote that in this example, the function doesn’t return any value as we are using the pipe operator, the final result is the median of the sum of column1 and column2, so you don’t need to use return statement.\n\n\nReturn value\nThe return value is the value that you’d like the function to return. In the example above, the function returns the median of the sum of the two columns. It’s important to always return a value and not rely on the automatic function capability of R to return the last value.\nTo call a function, you simply need to invoke it by its name and pass in any necessary arguments. For example:\n\ncalculate_sum_median(x)\n\nNow let’s see how we can use this function on a subset of the Liempe data:\n\nliempe_data <- read.csv(\"liempe-climate-data.csv\")\n\ncalculate_sum_median <- function(liempe_data){\n  y <- sum(liempe_data$tmp, liempe_data$rainfall)\n  z <- median(y)\n  return(z)\n}\n\nHere is an example of how you can re-write the above function using the Tidyverse syntax:\n\nlibrary(tidyverse)\n\nliempe_data <- read_csv(\"liempe-climate-data.csv\")\n\ncalculate_sum_median <- function(liempe_data){\n  liempe_data %>% \n    select(tmp, rainfall) %>% \n    summarize(sum = sum(tmp + rainfall)) %>% \n    pull(sum) %>% \n    median()\n}\n\nIn this example, we first load the Tidyverse library, then we read in the \"liempe-climate-data.csv\" using the read_csv() function from readr package, which is part of the Tidyverse.\nWe then define our function calculate_sum_median() , which takes in the dataframe “liempe_data” as an argument. Inside the function, we use the pipe operator(%>%) to chain together several Tidyverse functions to achieve the same result as the previous example.\nWe first select the columns \"tmp\" and \"rainfall\" using the select() function, then we use the summarize() function to calculate the sum of these two columns and store it in a new variable \"sum\". We then use the pull() function to extract the value of \"sum\" and finally, we use the median() function to calculate the median of this value.\nNote that in this example, the function doesn’t return any value as we are using the pipe operator, the final result is the median of the sum of tmp and rainfall, so you don’t need to use return statement.\nAnd then what…\nWe have to \"invoke\" or \"call\" the function\n\ncalculate_sum_median(x)\n\nWonderful! Now shall we try those previous steps together on a subset of the Liempe data?\n\nliempe_data <- read.csv(\"liempe-climate-data.csv\")\n\n\n\n\n\n\n\nQuestion?\n\n\n\nWhat are the set of instructions you would like to execute?\n\n\n\ny <- sum(liempe_data$tmp, liempe_data$rainfall)\nz <- median(y) \n\n\n\n\n\n\n\nTip\n\n\n\nBE SURE to remove these values from your global environment!\n\n\nLet’s turn that into a function\n\nName (Function declaration and curly brackets)\nFunction arguments\nFunction body\nReturn statement\n\nRemember our previous function?\n\ncalculate_sum_median <- function(x){\n  y <- sum(x$column1, x$column2)\n  z <- median(y)\n  return(z)\n}\n\nLet’s use this same function and change it to facilitate our dataset below:\n\ncalculate_sum_median <- function(liempe_data){\n  y <- sum(liempe_data$tmp, liempe_data$rainfall)\n  z <- median(y)\n  return(z)\n}\n\nAs with everything in R (programming), you can write the same thing in many ways! How about we write same function subsetting the dataset using brackets?\n\ncalculate_sum_mean <- function(liempe_data) {\n  y <- mean(liempe_data[, \"rainfall\"])\n  z <- mean(liempe_data[, \"tmp\"])\n  return(z)\n}\n\n\ncalculate_sum_mean(liempe_data)\n\nNow, let’s invoke the function:\n\nmedian_temp_rain <- calculate_sum_median(liempe_data)\n\n\nWe can also check this answer using a function we used before! \nsummary(y)\n\n\n\n\n\n\n\nTip!: Function indentation\n\n\n\n\nThis is how you can indent your function. Ctl + I (Windows)\nCheck what Ctrl + Shift + A does\nAlso try Shift tab to remove any indentation"
  },
  {
    "objectID": "functions.html#writing-your-own-functions",
    "href": "functions.html#writing-your-own-functions",
    "title": "8  Custom Functions",
    "section": "Writing your own functions",
    "text": "Writing your own functions\nLet’s get started on creating your own custom functions. Let’s partner up, for some pair programming - it’s even more fun together!\n\n\n\n\n\n\nExercise 1: Create a two argument function and return one variable\n\n\n\n\n\nPossible solution:\n\n# Create the function\nsquareAddition <- function(x, y){\n  x_squared <- x^2\n  y_squared <- y^2\n  sum_of_squares <- x_squared + y_squared\n  return(sum_of_squares)\n} \n\n#Check that the functioon works\nresult_square <- squareAddition(5,7) \n\n\n\n\n\n\n\n\n\n\nExercise 2: Create a one argument function\n\n\n\n\nHow would you create a function that inputs the liempe dataframe,\n\ncalculates both the mean rainfall and\nthe mean temperature for all observations,\nand then returns only the mean temperature?\n\nHow would you then invoke/call the function and assign it to a variable?\n\n\n\n\n\n\n\n\n\nExercise 3 : Create a function that inputs two arguments\n\n\n\n\nHow would you create a function that inputs two arguments: the liempe dataframe and a number (x), then;\n\nCalculates the mean temperature of the dataset\nSquares the number (x)\nAdds the temperature mean and the squared number together\nReturns the value\n\nHow would you then invoke/call the function and assign it to a variable?\n\n\n\n\n\n\n\n\n\n\nExercise 3 (Possible solution ) : Create a function that inputs two arguments\n\n\n\n\n\n\nsquareAdditionMultiple <- function(x, y){\n  x_squared <- x^2\n  y_squared <- y^2\n  sum_of_squares <- x_squared + y_squared\n  return(list(x_squared = x_squared, \n              y_squared = y_squared,\n              sum_of_squares = sum_of_squares))\n  } \nh\n\nresult_square_all <- squareAdditionMultiple(5,7) \n\nx_squared <- result_square_all$x_squared\ny_squared <- result_square_all$y_squared\nsum_of_squares <- result_square_all$sum_of_squares\n\n\n\n\n\n\n\n\n\n\nExercise 4: Two argument function / return multiple variables\n\n\n\n\nHow would you create a function that takes two arguments; the liempe dataset and a year,\n\nthen calculates the mean rainfall and\nthe mean temperature for the given year, returning the year, mean rainfall and mean temperature.\n\n\n\n\n\n\n\n\nTip! Perhaps you may like to subset the data first.\n\n\n\ni.e. Remember the subset function:\n\nsubset(liempe_data, Year == year_of_interest)\n\n\n\n\nHow would you then invoke/call the function and assign it to avariable?\nHow would you access all three variables, the mean rainfall, temperature and the year?\n\n\n\nGreat job!!! You are now a fully fledged creator of functions! Now I hope that you will go on to automate and create functions in your code, especially for those computations that you repeatedly run. Start simple, with what you learnt today and before you know it you’ll become more confident to program in a ‘functional’ style!"
  },
  {
    "objectID": "data_wrangling.html#subsetting",
    "href": "data_wrangling.html#subsetting",
    "title": "6  Data Wrangling",
    "section": "Subsetting",
    "text": "Subsetting\n\nSubsetting data frames\nThere are a number of operators that can be used to extract subsets of R objects.\n\n[] always returns an object of the same class as the original; can be used to select more than one element (there is one exception)\n[[]] is used to extract elements of a list or a data frame; it can only be used to extract a single element and the class of the returned object will not necessarily be a list or data frame\n$ is used to extract elements of a list or data frame by name; semantics are similar to that of [[]].\n\n\n\n\n\n\n\nData frames refresher\n\n\n\n\nData frames are used to store tabular data\nThey are represented as a special type of list where every element of the list has to have the same length\nEach element of the list can be thought of as a column and the length of each element of the list is the number of rows\nUnlike matrices, data frames can store different classes of objects in each column (just like lists); matrices must have every element be the same class\nData frames also have a special attribute called row.names\nData frames are usually created by calling read.table() or read.csv()\nCan be converted to a matrix by calling data.matrix()\n\n\n# Creating and exploring a dataframe\nx <- data.frame(foo = 1:4, bar = c(T, T, F, F))\nx\n\n  foo   bar\n1   1  TRUE\n2   2  TRUE\n3   3 FALSE\n4   4 FALSE\n\nnrow(x)\n\n[1] 4\n\nncol(x)\n\n[1] 2\n\n\n\n\nData Frame Subsetting If provided with a single value, data frames assume you want to subset a column or columns - multiple values then the data frame is treated as a matrix.\n\n# create a data frame\ndf = data.frame(a = 1:2, b = 3:4) \n\n# returns an object of the same class as the original\ndf[1] \n\n  a\n1 1\n2 2\n\n# class of the returned object will not necessarily be a list or data frame\ndf[[1]] \n\n[1] 1 2\n\n# class of the returned object will not necessarily be a list or data frame\ndf[, \"a\"] \n\n[1] 1 2\n\n# returns an object of the same class as the original\ndf[\"a\"] \n\n  a\n1 1\n2 2\n\n# returns an object of the same class as the original\ndf[, \"a\", drop = FALSE] \n\n  a\n1 1\n2 2\n\ndf[1, ] \n\n  a b\n1 1 3\n\ndf[c(\"a\",\"b\",\"a\")]\n\n  a b a.1\n1 1 3   1\n2 2 4   2\n\n\nSubsetting a single column from a data frame\nLet’s load in yielddata into a data frame. This contains the 100 grain weight of maize grain at ZARI. The data are on planting dates, nitrogen fertilizer rates (n1, n2, n3) & maize cultivars (v1, v2, v3). Using the str command, we find that there are 81 observations in this data frame\n\n#load the yielddata dataset\ndata.df <- read.csv(\"data/yielddata.csv\",header=T,stringsAsFactors=T)\n# display the first 6 rows of the data frame\nhead(data.df)\n\n  plotno rep pd variety nrate x_100_grain_wt\n1      1   1  1      v2    n2           4.30\n2      3   1  1      v2    n1           4.47\n3     20   1  1      v2    n3           3.34\n4     40   2  1      v2    n1           3.79\n5     41   2  1      v2    n3           4.59\n6     49   2  1      v2    n2           3.94\n\n# check the structure of the data \nstr(data.df)  \n\n'data.frame':   81 obs. of  6 variables:\n $ plotno        : int  1 3 20 40 41 49 62 66 81 4 ...\n $ rep           : int  1 1 1 2 2 2 3 3 3 1 ...\n $ pd            : int  1 1 1 1 1 1 1 1 1 2 ...\n $ variety       : Factor w/ 3 levels \"v1\",\"v2\",\"v3\": 2 2 2 2 2 2 2 2 2 2 ...\n $ nrate         : Factor w/ 3 levels \"n1\",\"n2\",\"n3\": 2 1 3 1 3 2 2 3 1 2 ...\n $ x_100_grain_wt: num  4.3 4.47 3.34 3.79 4.59 3.94 2.49 3.86 3.07 4.39 ...\n\n\nLet’s try to get One Column after from the data frame named yielddata loaded into R, we can take subsets of these 81 observations. First, let’s assume we just want to pull out the column of rep, pd, variety, nrate & x_100_grain_wt. There are two ways we can do this: - specifying the column by name, or specifying - the column by its order of appearance.\nThe general form for pulling information from data frames is data.frame[rows,columns]. it follows that you can get the first column in either of these two ways:\n\n# get all rows, but only the third column\ndata.df[ ,3]         \n\n [1] 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 2 2\n[39] 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3\n[77] 3 3 3 3 3\n\n# get all rows, and only the column named \"pd\"\ndata.df[ ,c(\"pd\")]   \n\n [1] 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 2 2\n[39] 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3\n[77] 3 3 3 3 3\n\n\nSubsetting multiple columns from a data frame If you want more than one column, you can specify the column numbers or the names of the variables that you want to extract. For example if you want to get the pd, variety, & nrate columns, you would do this:\n\n# get all rows, but only 3rd and 4th columns\ndata.df[,c(3,4)]  \n\n   pd variety\n1   1      v2\n2   1      v2\n3   1      v2\n4   1      v2\n5   1      v2\n6   1      v2\n7   1      v2\n8   1      v2\n9   1      v2\n10  2      v2\n11  2      v2\n12  2      v2\n13  2      v2\n14  2      v2\n15  2      v2\n16  2      v2\n17  2      v2\n18  2      v2\n19  3      v2\n20  3      v2\n21  3      v2\n22  3      v2\n23  3      v2\n24  3      v2\n25  3      v2\n26  3      v2\n27  3      v2\n28  1      v3\n29  1      v3\n30  1      v3\n31  1      v3\n32  1      v3\n33  1      v3\n34  1      v3\n35  1      v3\n36  1      v3\n37  2      v3\n38  2      v3\n39  2      v3\n40  2      v3\n41  2      v3\n42  2      v3\n43  2      v3\n44  2      v3\n45  2      v3\n46  3      v3\n47  3      v3\n48  3      v3\n49  3      v3\n50  3      v3\n51  3      v3\n52  3      v3\n53  3      v3\n54  3      v3\n55  1      v1\n56  1      v1\n57  1      v1\n58  1      v1\n59  1      v1\n60  1      v1\n61  1      v1\n62  1      v1\n63  1      v1\n64  2      v1\n65  2      v1\n66  2      v1\n67  2      v1\n68  2      v1\n69  2      v1\n70  2      v1\n71  2      v1\n72  2      v1\n73  3      v1\n74  3      v1\n75  3      v1\n76  3      v1\n77  3      v1\n78  3      v1\n79  3      v1\n80  3      v1\n81  3      v1\n\n# get all rows, only \"pd\" & \"variety\" columns              \ndata.df[,c(\"pd\",\"variety\")]    \n\n   pd variety\n1   1      v2\n2   1      v2\n3   1      v2\n4   1      v2\n5   1      v2\n6   1      v2\n7   1      v2\n8   1      v2\n9   1      v2\n10  2      v2\n11  2      v2\n12  2      v2\n13  2      v2\n14  2      v2\n15  2      v2\n16  2      v2\n17  2      v2\n18  2      v2\n19  3      v2\n20  3      v2\n21  3      v2\n22  3      v2\n23  3      v2\n24  3      v2\n25  3      v2\n26  3      v2\n27  3      v2\n28  1      v3\n29  1      v3\n30  1      v3\n31  1      v3\n32  1      v3\n33  1      v3\n34  1      v3\n35  1      v3\n36  1      v3\n37  2      v3\n38  2      v3\n39  2      v3\n40  2      v3\n41  2      v3\n42  2      v3\n43  2      v3\n44  2      v3\n45  2      v3\n46  3      v3\n47  3      v3\n48  3      v3\n49  3      v3\n50  3      v3\n51  3      v3\n52  3      v3\n53  3      v3\n54  3      v3\n55  1      v1\n56  1      v1\n57  1      v1\n58  1      v1\n59  1      v1\n60  1      v1\n61  1      v1\n62  1      v1\n63  1      v1\n64  2      v1\n65  2      v1\n66  2      v1\n67  2      v1\n68  2      v1\n69  2      v1\n70  2      v1\n71  2      v1\n72  2      v1\n73  3      v1\n74  3      v1\n75  3      v1\n76  3      v1\n77  3      v1\n78  3      v1\n79  3      v1\n80  3      v1\n81  3      v1\n\n\nIf you want more than one column and those columns are next to each other, you can do this:\n\ndata.df[,c(2:6)]\n\n   rep pd variety nrate x_100_grain_wt\n1    1  1      v2    n2           4.30\n2    1  1      v2    n1           4.47\n3    1  1      v2    n3           3.34\n4    2  1      v2    n1           3.79\n5    2  1      v2    n3           4.59\n6    2  1      v2    n2           3.94\n7    3  1      v2    n2           2.49\n8    3  1      v2    n3           3.86\n9    3  1      v2    n1           3.07\n10   1  2      v2    n2           4.39\n11   1  2      v2    n3           3.78\n12   1  2      v2    n1           3.75\n13   2  2      v2    n1           2.97\n14   2  2      v2    n2           3.46\n15   2  2      v2    n3           3.78\n16   3  2      v2    n1           4.32\n17   3  2      v2    n2           2.01\n18   3  2      v2    n3           4.63\n19   1  3      v2    n3           2.43\n20   1  3      v2    n1           3.94\n21   1  3      v2    n2           3.94\n22   2  3      v2    n3           3.57\n23   2  3      v2    n2           4.35\n24   2  3      v2    n1           2.06\n25   3  3      v2    n1           3.50\n26   3  3      v2    n2           3.40\n27   3  3      v2    n3           3.23\n28   1  1      v3    n2           4.84\n29   1  1      v3    n1           3.44\n30   1  1      v3    n3           5.18\n31   2  1      v3    n3           5.20\n32   2  1      v3    n1           4.57\n33   2  1      v3    n2           5.40\n34   3  1      v3    n3           4.62\n35   3  1      v3    n1           4.33\n36   3  1      v3    n2           3.45\n37   1  2      v3    n2           4.27\n38   1  2      v3    n1           3.81\n39   1  2      v3    n3           4.74\n40   2  2      v3    n3           3.55\n41   2  2      v3    n1           3.46\n42   2  2      v3    n2           2.53\n43   3  2      v3    n3           4.39\n44   3  2      v3    n2           2.79\n45   3  2      v3    n1           3.45\n46   1  3      v3    n2           3.80\n47   1  3      v3    n1           3.94\n48   1  3      v3    n3           2.53\n49   2  3      v3    n3           3.42\n50   2  3      v3    n1           2.82\n51   2  3      v3    n2           3.37\n52   3  3      v3    n3           2.98\n53   3  3      v3    n2           3.59\n54   3  3      v3    n1           3.38\n55   1  1      v1    n2           4.30\n56   1  1      v1    n1           2.58\n57   1  1      v1    n3           2.87\n58   2  1      v1    n2           2.81\n59   2  1      v1    n1           4.04\n60   2  1      v1    n3           4.03\n61   3  1      v1    n1           2.37\n62   3  1      v1    n2           2.50\n63   3  1      v1    n3           2.56\n64   1  2      v1    n2           3.68\n65   1  2      v1    n1           3.19\n66   1  2      v1    n3           2.95\n67   2  2      v1    n3           3.74\n68   2  2      v1    n2           2.84\n69   2  2      v1    n1           2.21\n70   3  2      v1    n3           2.52\n71   3  2      v1    n1           3.96\n72   3  2      v1    n2           2.82\n73   1  3      v1    n2           2.77\n74   1  3      v1    n3           3.60\n75   1  3      v1    n1           3.01\n76   2  3      v1    n1           3.34\n77   2  3      v1    n3           3.08\n78   2  3      v1    n2           3.59\n79   3  3      v1    n1           3.18\n80   3  3      v1    n2           3.18\n81   3  3      v1    n3           3.34\n\n\nGetting One Row You can get the first row similarly to how you got the first column, and any other row the same way:\n\n# get first row, and all columns\ndata.df[1,]   \n\n  plotno rep pd variety nrate x_100_grain_wt\n1      1   1  1      v2    n2            4.3\n\n# get 72nd row, and all columns      \ndata.df[72,]        \n\n   plotno rep pd variety nrate x_100_grain_wt\n72     71   3  2      v1    n2           2.82\n\n\nGetting Multiple Rows If you want more than one row, you can specify the row numbers you want like this:\n\ndata.df[c(1:3,5,6),]\n\n  plotno rep pd variety nrate x_100_grain_wt\n1      1   1  1      v2    n2           4.30\n2      3   1  1      v2    n1           4.47\n3     20   1  1      v2    n3           3.34\n5     41   2  1      v2    n3           4.59\n6     49   2  1      v2    n2           3.94\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry to get row (10 to 41) and columns (2 to 5) from the yielddata dataset\n\n\n\n\nSubsetting Lists\n\nx <- list(foo = 1:4, bar = 0.6)\nx[1]\n\n$foo\n[1] 1 2 3 4\n\nx[[1]]\n\n[1] 1 2 3 4\n\nx$bar\n\n[1] 0.6\n\nx[[\"bar\"]]\n\n[1] 0.6\n\nx[\"bar\"]\n\n$bar\n[1] 0.6\n\n\n\nx <- list(foo = 1:4, bar = 0.6, baz = \"hello\")\nx\n\n$foo\n[1] 1 2 3 4\n\n$bar\n[1] 0.6\n\n$baz\n[1] \"hello\"\n\nx[c(1, 3)]\n\n$foo\n[1] 1 2 3 4\n\n$baz\n[1] \"hello\"\n\n\nThe [[]] operator can be used with computed indices; $ can only be used with literal names.\n\nx <- list(foo = 1:4, bar = 0.6, baz = \"hello\")\nname <- \"foo\"\n# computed index for 'foo'\nx[[name]] \n\n[1] 1 2 3 4\n\n# element 'name' doesn't exist!\nx$name \n\nNULL\n\nx$foo\n\n[1] 1 2 3 4\n\n\nSubsetting Nested Elements of a List The [[]] can take an integer sequence.\n\nx <- list(a = list(10, 12, 14), b = c(3.14, 2.81))\nx\n\n$a\n$a[[1]]\n[1] 10\n\n$a[[2]]\n[1] 12\n\n$a[[3]]\n[1] 14\n\n\n$b\n[1] 3.14 2.81\n\nx[[c(1, 3)]]\n\n[1] 14\n\nx[[1]][[3]]\n\n[1] 14\n\nx[[c(2, 1)]]\n\n[1] 3.14\n\n\n\n\nSubsetting a Matrix\nMatrices can be subsetted in the usual way with (i,j) type indices. Indices can also be missing. e.g. x[1, ] reads rows only, x[, 2] reads columns only.\n\nx <- matrix(1:6, 2, 3)\nx\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\nx[1, 2] # R reads rows first and columns second\n\n[1] 3\n\nx[2, 1] # Reads both rows, columns\n\n[1] 2\n\n# Indices can also be missing.\nx[1, ]  # Reads rows only\n\n[1] 1 3 5\n\nx[, 2]  # Reads columns only\n\n[1] 3 4\n\n\nBy default, when a single element of a matrix is retrieved, it is returned as a vector of length 1 rather than a 1 ? 1 matrix. This behavior can be turned off by setting drop = FALSE.\n\nx <- matrix(1:6, 2, 3)\nx\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\nx[1, 2]\n\n[1] 3\n\nx[1, 2, drop = FALSE]\n\n     [,1]\n[1,]    3\n\n\nSimilarly, subsetting a single column or a single row will give you a vector, not a matrix (by default).\n\nx <- matrix(1:6, 2, 3)\nx\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\nx[1, ] # displays all first row and all columns\n\n[1] 1 3 5\n\nx[1, , drop = FALSE]\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n\n\nPartial matching of names is allowed with [[]] and $.\n\nx <- list(aardvark = 1:5)\nx\n\n$aardvark\n[1] 1 2 3 4 5\n\nx$a\n\n[1] 1 2 3 4 5\n\nx[[\"a\"]]\n\nNULL\n\nx[[\"a\", exact = FALSE]]\n\n[1] 1 2 3 4 5\n\n\n\n\nSubsetting a Vector\nVectors are basic objects in R and they can be subsetted using the [] operator.\n\nx <- c(\"a\", \"b\", \"c\", \"c\", \"d\", \"a\")\n# Extract the first element\nx[1] \n\n[1] \"a\"\n\n# Extract the second element\nx[2] \n\n[1] \"b\"\n\n\nThe [] operator can be used to extract multiple elements of a vector by passing the operator an integer sequence. Here we extract the first four elements of the vector.\n\nx[1:4]\n\n[1] \"a\" \"b\" \"c\" \"c\"\n\n\nThe sequence does not have to be in order; you can specify any arbitrary integer vector.\n\nx[c(1, 3, 4)]\n\n[1] \"a\" \"c\" \"c\"\n\n\nWe can also pass a logical sequence to the [] operator to extract elements of a vector that satisfy a given condition. For example, here we want the elements of x that come lexicographically after the letter a.\n\nu <- x > \"a\"\nu\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE\n\n# this displays all the elements fulfiling the condition\nx[u]  \n\n[1] \"b\" \"c\" \"c\" \"d\"\n\n\nAnother, more compact, way to do this would be to skip the creation of a logical vector and just subset the vector directly with the logical expression.\n\nx[x > \"a\"]\n\n[1] \"b\" \"c\" \"c\" \"d\"\n\n\nIt’s frequently necessary to extract some of the elements of a larger vector.In R you can use square brackets to select an individual element or group of elements:\n\nx <- c(5,9,2,14,-4)\nx[3]\n\n[1] 2\n\n\n\n\n\n\n\n\nnote indexing starts from 1\n\n\n\n\nx[c(2,3,5)]\n\n[1]  9  2 -4\n\nx[1:3]\n\n[1] 5 9 2\n\nx[3:length(x)]\n\n[1]  2 14 -4\n\n\nThere are two other methods for getting subvectors. The first is using a logical vector (i.e. containing TRUE and FALSE) of the same length:\n\nx > 4\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE\n\nx[x > 4]\n\n[1]  5  9 14\n\n\nor using negative indices to specify which elements should not be selected:\n\nx[-1]\n\n[1]  9  2 14 -4\n\nx[-c(1,4)]\n\n[1]  9  2 -4\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that this is rather different to what other languages such as C or Python would interpret negative indices to mean.)\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe built-in vector LETTERS contains the uppercase letters of the alphabet. Produce a vector of\n\nthe first 12 letters;\nthe odd ‘numbered’ letters;\nthe English consonants.\n\n\n\n\n\nRemoving NA Values\nHere we will use a complete.cases function in R. Find Complete Cases returns a logical vector indicating which cases are complete, i.e., have no missing values or NAs.\n\n# read the help pages on how to use the complete.cases function\n?complete.cases\n\nA common task is to remove missing values (NAs).\n\n# Create a vector with some missing values\nx <- c(1, 2, NA, 4, NA, 5) \n# Create a logical vector indicating which elements are missing\nbad <- is.na(x)\n# Use the logical vector to subset the original vector\nx[!bad]\n\n[1] 1 2 4 5\n\n\nWhat if there are multiple things and you want to take the subset with no missing values?\n\nx <- c(1, 2, NA, 4, NA, 5)\ny <- c(\"a\", \"b\", NA, \"d\", NA, \"f\")\ngood <- complete.cases(x, y)\nx[good]\n\n[1] 1 2 4 5\n\ny[good]\n\n[1] \"a\" \"b\" \"d\" \"f\"\n\n\nLet’s use airquality, one of R’s built in datasets.\n\n# Load the airquality dataset and this shows the first six rows\nairquality[1:6, ] \n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\ngood <- complete.cases(airquality)\n# all rows containing an NA are removed completely\nairquality[good, ][1:6, ] \n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n7    23     299  8.6   65     5   7\n8    19      99 13.8   59     5   8\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWrite a script to remove NAs from airquality using columns\n\n\n\n\nSubsetting a factor\nFactors are used to represent categorical variables with fixed possible values. Factors can be created with the factor function. The levels of a factor are the possible values it can take; by default these are ordered alphabetically. The levels function can be used to get (and set) the levels of a factor.\n\n\n\n\n\n\nR factors recap\n\n\n\n\nFactors are the data objects which are used to categorize the data and store it as levels.\nThey can store both strings and integers.\nThey are useful in the columns which have a limited number of unique values.\nLike \"Male\", \"Female\" and True, False etc.\nThey are useful in data analysis for statistical modeling.\nFactors are created using the factor() function by taking a vector as input\n\n\n\n\n# As an example, let's create a vector as input\ndata <- c(\"East\",\"West\",\"East\",\"North\",\"North\",\"East\",\"West\",\"West\",\"West\",\"East\",\"North\")\n# print the data\nprint(data)\n\n [1] \"East\"  \"West\"  \"East\"  \"North\" \"North\" \"East\"  \"West\"  \"West\"  \"West\" \n[10] \"East\"  \"North\"\n\n# check if the data as a factor\nprint(is.factor(data))\n\n[1] FALSE\n\n\nApply the factor function on the vector data we created.\n\n# we are applying the factor() function to data\nfactor_data <- factor(data) \n# save the data into the `factor_data`\n\nprint(factor_data)\n\n [1] East  West  East  North North East  West  West  West  East  North\nLevels: East North West\n\nprint(is.factor(factor_data))\n\n[1] TRUE\n\n\n\nFactors in Data Frame\nOn creating any data frame with a column of text data, R treats the text column as categorical data and creates factors on it.\n\n# Create the vectors for data frame.\nheight <- c(132,151,162,139,166,147,122)\nweight <- c(48,49,66,53,67,52,40)\ngender <- c(\"male\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\")\n\n# Create the data frame.\ninput_data <- data.frame(height, weight, gender)\nprint(input_data)\n\n  height weight gender\n1    132     48   male\n2    151     49   male\n3    162     66 female\n4    139     53 female\n5    166     67   male\n6    147     52 female\n7    122     40   male\n\n# Test if the gender column is a factor.\nprint(is.factor(input_data$gender))\n\n[1] FALSE\n\n# Change the gender column to a factor.\ninput_data$gender <- factor(input_data$gender)\n\n# Print the gender column so see the levels.\nprint(input_data$gender)\n\n[1] male   male   female female male   female male  \nLevels: female male\n\n\n\n\nChanging the Order of Levels\nThe order of the levels in a factor can be changed by applying the factor() function again with new order of the levels.\n\n# Create the vector for data frame.\n\ndata <- c(\"East\", \"West\", \"East\", \"North\", \"North\", \"East\",\n          \"West\", \"West\", \"West\", \"East\", \"North\")\n\n# Create the factors\nfactor_data <- factor(data)\nprint(factor_data)\n\n [1] East  West  East  North North East  West  West  West  East  North\nLevels: East North West\n\n# Apply the factor function with required order of the level.\nnew_order_data <- factor(factor_data,levels = c(\"East\",\"West\",\"North\"))\nprint(new_order_data)\n\n [1] East  West  East  North North East  West  West  West  East  North\nLevels: East West North\n\n\n\n\nGenerating Factor Levels\nWe can generate factor levels by using the gl() function. It takes two integers as input which indicates how many levels and how many times each level. e.g. gl(n, k, labels) where:\n\nn is a integer giving the number of levels.\nk is a integer giving the number of replications.\nlabels is a vector of labels for the resulting factor levels.\n\nFor example, if we want to create a factor with 3 levels and each level should be repeated 4 times, we can use the following code.\n\nv <- gl(3, 4, labels = c(\"Chitedze\", \"Liempe\", \"Domboshava\"))\nprint(v)\n\n [1] Chitedze   Chitedze   Chitedze   Chitedze   Liempe     Liempe    \n [7] Liempe     Liempe     Domboshava Domboshava Domboshava Domboshava\nLevels: Chitedze Liempe Domboshava\n\n\nYou can subset factors in a similar way that you subset vectors. As usual, [ ] is the key! However, R has some interesting behavior when you want to remove a factor level from your analysis.For example to subset the first name from the above example\n\n# select the first name still returns all the levels\nv[1]        \n\n[1] Chitedze\nLevels: Chitedze Liempe Domboshava\n\n# using the drop=TRUE only gives the desired factor & levels      \nv[1, drop=TRUE]   \n\n[1] Chitedze\nLevels: Chitedze\n\n# select the first 2 names but still returns all the levels\nv[1:7]      \n\n[1] Chitedze Chitedze Chitedze Chitedze Liempe   Liempe   Liempe  \nLevels: Chitedze Liempe Domboshava\n\n# using the drop=TRUE only gives the desired factor & levels      \nv[1:7, drop=TRUE]   \n\n[1] Chitedze Chitedze Chitedze Chitedze Liempe   Liempe   Liempe  \nLevels: Chitedze Liempe\n\n\nAnother example of subsetting a factor is shown below.\n\n# Factor Subsetting\n(x = factor(c(\"BS\", \"MS\", \"PhD\", \"MS\")))\n\n[1] BS  MS  PhD MS \nLevels: BS MS PhD\n\nx[1:2]\n\n[1] BS MS\nLevels: BS MS PhD\n\n\nR selects the BS MS at the first and second position, but left the MS level behind. A better plan would have been to tell R to drop the PhD level entirely. To do that, add drop = TRUE to the subsetting command.\n\nx[1:2, drop=TRUE]\n\n[1] BS MS\nLevels: BS MS"
  },
  {
    "objectID": "big_data.html#introduction",
    "href": "big_data.html#introduction",
    "title": "7  Wrangling Big Data",
    "section": "Introduction",
    "text": "Introduction\nBig Data is a catch phrase for any dataset or data application that does not fit into available RAM on one system. R has a few packages for big data support e.g bigmemory and ff; and also some uses of parallelism to accomplish the same goal using Hadoop and MapReduce;\nFor datasets with size in the range 10GB, bigmemory and ff handle themselves well; For larger datasets, use Hadoop.\nWhy is it important to use bigmemory and ff?\n\nR reads data into RAM all at once, if using the usual read.table() function.\nObjects in R live in memory entirely.\nKeeping unnecessary data in RAM will cause R to choke eventually.\nSpecifically,\n\n\non most systems it is not possible to use more than 2GB of memory.\nthe range of indexes that can be used is limited due to lack of a 64 bit integer data type in R and R64.\non 32 bit systems, the maximum amount of virtual memory space is limited to between 2 and 4GB.\nrelying on virtual memory will cause the system to grind to a halt “thrashing”\n\nThere are two major solutions in R:\n\nbigmemory: It is ideal for problems involving the analysis in R of manageable subsets of the data, or when an analysis is conducted mostly in C++.” It’s part of the \\big“ family, some of which we will discuss.\nff: file-based access to datasets that cannot fit in memory.\ncan also use databases which provide fast read/write access for piecemeal analysis.\n\nThe big family consists of several packages for performing tasks on large datasets.\n\nbigmemory is our focus.\nbiganalytics provides analysis routines on big.matrix such as GLM and bigkmeans.\nsynchronicity adds Boost mutex functionality to R.\nbigtabulate adds table and split-like support for R matrices and big.matrix memory efficiently.\nbigalgebra provides BLAS and LAPACK linear algebra routines for native R matrices and big.matrix.\nbigvideo provides video camera streaming via OpenCV.\n\n\n\n\n\n\n\nExercise\n\n\n\n\n# install.packages(c(\"bigmemory\", \"biganalytics\"))\ninstall.packages(c(\"bigmemory\", \"biganalytics\"))\n\n# load the packages\nlibrary(bigmemory)\nlibrary(biganalytics)\n\noptions(bigmemory.typecast.warning=FALSE)\n\n# create a big.matrix\nA <- big.matrix(5000, 5000, type=\"char\", init=0)\n\n# Fill the matrix by randomly picking 20% of the positions for a 1.\nx <- sample(1:5000,size=5000,replace=TRUE)\nx\ny <- sample(1:5000,size=5000,replace=TRUE)\ny\n\nfor(i in 1:5000) {\n  A[x[i],y[i]] <- 1\n}\n\n# Get the location in RAM of the pointer to A.\ndesc <- describe(A)\ndesc\n\n# Write it to disk.\ndput(desc, file=\"A.desc\")\nsums <- colsum(A, 1:20)\nsums\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n# Session 2\nlibrary(bigmemory)\nlibrary(biganalytics)\n\n# Read the pointer from disk.\ndesc <- dget(\"A.desc\")\ndesc\n\n# Attach to the pointer in RAM.\nA <- attach.big.matrix(desc)\nA\n\n# Check our results.\nsums <- colsum(A, 1:20)\nsums"
  },
  {
    "objectID": "data_visualisation.html#plots-and-graphs",
    "href": "data_visualisation.html#plots-and-graphs",
    "title": "9  Data Visualisation",
    "section": "Plots and Graphs",
    "text": "Plots and Graphs\nThe objective of this section is to provide information on the topic under consideration, along with examples and exercises. You should be able to work through it in R or R studio. This section requires no additional functions or packages to be loaded.\nThe specific objective of the material in this script is to introduce you to different graphic used in R. By the end you should have a better understanding of the concepts you worked with before, and should be better-placed to start developing and editing scripts yourself. The particular topics we shall cover are:\n\nUnivariate graphs\nMultivariate graphs\nControlling layout\nPrinting graphs"
  },
  {
    "objectID": "data_visualisation.html#univariate-graphs",
    "href": "data_visualisation.html#univariate-graphs",
    "title": "9  Data Visualisation",
    "section": "Univariate graphs",
    "text": "Univariate graphs\nIn this section, we look at graphics that we may create with a single variable. This includes histograms, boxplots, bar charts, as well as QQ plots. These are usually important in checking the distribution of variables in your dataset or checking the residuals of a fitted model.\n\nHistogram\nThe function that is used to produce a histogram is the hist() function. A number of arguments are used in the hist() function.\nBefore you go further, recall that you can produce random numbers from a normal distribution by the use of the function rnorm(). We use this to simulate some random temperature data\n\n# generates a vector of 100 numbers with mean 0 and standard deviation 1\ntemperature<-rnorm(100,mean=0,sd=1)   \n\n# explore the data\nprint(temperature)\n\n  [1] -0.48414558  0.22775089 -0.19861062  0.33298555 -0.25922292 -0.18135381\n  [7]  0.49492353 -0.67290381  0.86565520  1.01123491 -0.49821498  0.45353421\n [13]  0.87878879  0.92300992  0.37361108 -0.05096956 -1.29408945 -0.64459686\n [19]  1.56113730  0.52869710 -1.86665520 -1.32752163  0.16778391  0.02480848\n [25]  0.88505765 -0.66023039  0.12481857  0.55597606  1.23427130  0.01284858\n [31] -0.51386786 -0.32518648 -0.62065309  0.32476843 -1.72501982 -1.42089220\n [37] -0.60668080 -0.93735572  2.27696154 -0.43018915 -1.07907058 -0.34178117\n [43]  0.33380877 -0.93906135 -0.50390644 -2.08445435 -0.23957185  0.52747913\n [49] -0.28435108 -0.61501869 -0.33989170  0.55883351  0.57943936  0.57064187\n [55] -0.79152452 -0.78414256 -0.87928915 -1.21015316  1.65797299  1.05739072\n [61] -0.95093460  1.53430075 -0.36390049 -0.65530950  0.66124311  1.14098667\n [67]  0.05739137 -0.05541524  0.59707877  0.43535500  0.33928795 -0.40389032\n [73]  0.39499798  0.60005541 -0.29667821  0.40369058 -1.41372770  0.58511274\n [79]  2.13884841 -0.09666472 -0.10648921  0.89339493 -0.54427301 -0.67267654\n [85]  1.93345220  0.24139074  1.48256448  0.77013903 -0.41782116 -0.76212393\n [91] -0.67341684 -0.92234521 -0.73516064  2.31776512  0.81607946 -0.54690642\n [97]  0.06409879  0.13314917  0.30848162  1.60541830\n\n#we can use the hist() function to make a histogram of these data \nhist(temperature)\n\n\n\n\nThis produces a histogram with grey bars, an x-axis labelled \"temperature\" and the title \"histogram of temperature\". All these three can be changed to your preference by adding extra arguments to the hist() function. Changing name of x-axis: This is done by adding argument xlab =\"name of axis\". Note that the name of axis is in quotation marks. Lets assume these data is temperature data\n\nhist(temperature, xlab=\"Temperature /?C\")  \n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote the \"solidus\" or / inbetween the name of the variable (Temperature) and the units. This is good practice for presenting units in axis labels, favoured by many publishers. The quantities on some axis labels have dimensions which are ratios, like kg per ha. This can be done \"kg/ha\" but that is not good scientific practice, particularly if you are using the solidus to indicate units as above. It is better to follow the \"ha\" with a power \"-1\". In R we can do this as follows (of course your data won’t be realistic for this example!)\n\n\n\nhist(temperature, xlab=expression(\"kg ha\"^-1)) \n\n\n\n\n\nChanging main title\nThis is done by adding argument main =\"name of main title\". Note that the name of axis is in quotation marks. Lets assume these data is soil temperature data.\n\nhist(temperature, xlab=\"Temperature /?C\", main=\"Soil temperature\")\n\n\n\n\n\n\nChanging colour of a histogram\n\n\n\n\n\n\nColour names (click to expand)\n\n\n\n\n\nThis is done by adding argument col =\"color\". There are various options of colors that can be used. You can check the various options of colors you can use by typing colors().\n\ncolors()\n\n  [1] \"white\"                \"aliceblue\"            \"antiquewhite\"        \n  [4] \"antiquewhite1\"        \"antiquewhite2\"        \"antiquewhite3\"       \n  [7] \"antiquewhite4\"        \"aquamarine\"           \"aquamarine1\"         \n [10] \"aquamarine2\"          \"aquamarine3\"          \"aquamarine4\"         \n [13] \"azure\"                \"azure1\"               \"azure2\"              \n [16] \"azure3\"               \"azure4\"               \"beige\"               \n [19] \"bisque\"               \"bisque1\"              \"bisque2\"             \n [22] \"bisque3\"              \"bisque4\"              \"black\"               \n [25] \"blanchedalmond\"       \"blue\"                 \"blue1\"               \n [28] \"blue2\"                \"blue3\"                \"blue4\"               \n [31] \"blueviolet\"           \"brown\"                \"brown1\"              \n [34] \"brown2\"               \"brown3\"               \"brown4\"              \n [37] \"burlywood\"            \"burlywood1\"           \"burlywood2\"          \n [40] \"burlywood3\"           \"burlywood4\"           \"cadetblue\"           \n [43] \"cadetblue1\"           \"cadetblue2\"           \"cadetblue3\"          \n [46] \"cadetblue4\"           \"chartreuse\"           \"chartreuse1\"         \n [49] \"chartreuse2\"          \"chartreuse3\"          \"chartreuse4\"         \n [52] \"chocolate\"            \"chocolate1\"           \"chocolate2\"          \n [55] \"chocolate3\"           \"chocolate4\"           \"coral\"               \n [58] \"coral1\"               \"coral2\"               \"coral3\"              \n [61] \"coral4\"               \"cornflowerblue\"       \"cornsilk\"            \n [64] \"cornsilk1\"            \"cornsilk2\"            \"cornsilk3\"           \n [67] \"cornsilk4\"            \"cyan\"                 \"cyan1\"               \n [70] \"cyan2\"                \"cyan3\"                \"cyan4\"               \n [73] \"darkblue\"             \"darkcyan\"             \"darkgoldenrod\"       \n [76] \"darkgoldenrod1\"       \"darkgoldenrod2\"       \"darkgoldenrod3\"      \n [79] \"darkgoldenrod4\"       \"darkgray\"             \"darkgreen\"           \n [82] \"darkgrey\"             \"darkkhaki\"            \"darkmagenta\"         \n [85] \"darkolivegreen\"       \"darkolivegreen1\"      \"darkolivegreen2\"     \n [88] \"darkolivegreen3\"      \"darkolivegreen4\"      \"darkorange\"          \n [91] \"darkorange1\"          \"darkorange2\"          \"darkorange3\"         \n [94] \"darkorange4\"          \"darkorchid\"           \"darkorchid1\"         \n [97] \"darkorchid2\"          \"darkorchid3\"          \"darkorchid4\"         \n[100] \"darkred\"              \"darksalmon\"           \"darkseagreen\"        \n[103] \"darkseagreen1\"        \"darkseagreen2\"        \"darkseagreen3\"       \n[106] \"darkseagreen4\"        \"darkslateblue\"        \"darkslategray\"       \n[109] \"darkslategray1\"       \"darkslategray2\"       \"darkslategray3\"      \n[112] \"darkslategray4\"       \"darkslategrey\"        \"darkturquoise\"       \n[115] \"darkviolet\"           \"deeppink\"             \"deeppink1\"           \n[118] \"deeppink2\"            \"deeppink3\"            \"deeppink4\"           \n[121] \"deepskyblue\"          \"deepskyblue1\"         \"deepskyblue2\"        \n[124] \"deepskyblue3\"         \"deepskyblue4\"         \"dimgray\"             \n[127] \"dimgrey\"              \"dodgerblue\"           \"dodgerblue1\"         \n[130] \"dodgerblue2\"          \"dodgerblue3\"          \"dodgerblue4\"         \n[133] \"firebrick\"            \"firebrick1\"           \"firebrick2\"          \n[136] \"firebrick3\"           \"firebrick4\"           \"floralwhite\"         \n[139] \"forestgreen\"          \"gainsboro\"            \"ghostwhite\"          \n[142] \"gold\"                 \"gold1\"                \"gold2\"               \n[145] \"gold3\"                \"gold4\"                \"goldenrod\"           \n[148] \"goldenrod1\"           \"goldenrod2\"           \"goldenrod3\"          \n[151] \"goldenrod4\"           \"gray\"                 \"gray0\"               \n[154] \"gray1\"                \"gray2\"                \"gray3\"               \n[157] \"gray4\"                \"gray5\"                \"gray6\"               \n[160] \"gray7\"                \"gray8\"                \"gray9\"               \n[163] \"gray10\"               \"gray11\"               \"gray12\"              \n[166] \"gray13\"               \"gray14\"               \"gray15\"              \n[169] \"gray16\"               \"gray17\"               \"gray18\"              \n[172] \"gray19\"               \"gray20\"               \"gray21\"              \n[175] \"gray22\"               \"gray23\"               \"gray24\"              \n[178] \"gray25\"               \"gray26\"               \"gray27\"              \n[181] \"gray28\"               \"gray29\"               \"gray30\"              \n[184] \"gray31\"               \"gray32\"               \"gray33\"              \n[187] \"gray34\"               \"gray35\"               \"gray36\"              \n[190] \"gray37\"               \"gray38\"               \"gray39\"              \n[193] \"gray40\"               \"gray41\"               \"gray42\"              \n[196] \"gray43\"               \"gray44\"               \"gray45\"              \n[199] \"gray46\"               \"gray47\"               \"gray48\"              \n[202] \"gray49\"               \"gray50\"               \"gray51\"              \n[205] \"gray52\"               \"gray53\"               \"gray54\"              \n[208] \"gray55\"               \"gray56\"               \"gray57\"              \n[211] \"gray58\"               \"gray59\"               \"gray60\"              \n[214] \"gray61\"               \"gray62\"               \"gray63\"              \n[217] \"gray64\"               \"gray65\"               \"gray66\"              \n[220] \"gray67\"               \"gray68\"               \"gray69\"              \n[223] \"gray70\"               \"gray71\"               \"gray72\"              \n[226] \"gray73\"               \"gray74\"               \"gray75\"              \n[229] \"gray76\"               \"gray77\"               \"gray78\"              \n[232] \"gray79\"               \"gray80\"               \"gray81\"              \n[235] \"gray82\"               \"gray83\"               \"gray84\"              \n[238] \"gray85\"               \"gray86\"               \"gray87\"              \n[241] \"gray88\"               \"gray89\"               \"gray90\"              \n[244] \"gray91\"               \"gray92\"               \"gray93\"              \n[247] \"gray94\"               \"gray95\"               \"gray96\"              \n[250] \"gray97\"               \"gray98\"               \"gray99\"              \n[253] \"gray100\"              \"green\"                \"green1\"              \n[256] \"green2\"               \"green3\"               \"green4\"              \n[259] \"greenyellow\"          \"grey\"                 \"grey0\"               \n[262] \"grey1\"                \"grey2\"                \"grey3\"               \n[265] \"grey4\"                \"grey5\"                \"grey6\"               \n[268] \"grey7\"                \"grey8\"                \"grey9\"               \n[271] \"grey10\"               \"grey11\"               \"grey12\"              \n[274] \"grey13\"               \"grey14\"               \"grey15\"              \n[277] \"grey16\"               \"grey17\"               \"grey18\"              \n[280] \"grey19\"               \"grey20\"               \"grey21\"              \n[283] \"grey22\"               \"grey23\"               \"grey24\"              \n[286] \"grey25\"               \"grey26\"               \"grey27\"              \n[289] \"grey28\"               \"grey29\"               \"grey30\"              \n[292] \"grey31\"               \"grey32\"               \"grey33\"              \n[295] \"grey34\"               \"grey35\"               \"grey36\"              \n[298] \"grey37\"               \"grey38\"               \"grey39\"              \n[301] \"grey40\"               \"grey41\"               \"grey42\"              \n[304] \"grey43\"               \"grey44\"               \"grey45\"              \n[307] \"grey46\"               \"grey47\"               \"grey48\"              \n[310] \"grey49\"               \"grey50\"               \"grey51\"              \n[313] \"grey52\"               \"grey53\"               \"grey54\"              \n[316] \"grey55\"               \"grey56\"               \"grey57\"              \n[319] \"grey58\"               \"grey59\"               \"grey60\"              \n[322] \"grey61\"               \"grey62\"               \"grey63\"              \n[325] \"grey64\"               \"grey65\"               \"grey66\"              \n[328] \"grey67\"               \"grey68\"               \"grey69\"              \n[331] \"grey70\"               \"grey71\"               \"grey72\"              \n[334] \"grey73\"               \"grey74\"               \"grey75\"              \n[337] \"grey76\"               \"grey77\"               \"grey78\"              \n[340] \"grey79\"               \"grey80\"               \"grey81\"              \n[343] \"grey82\"               \"grey83\"               \"grey84\"              \n[346] \"grey85\"               \"grey86\"               \"grey87\"              \n[349] \"grey88\"               \"grey89\"               \"grey90\"              \n[352] \"grey91\"               \"grey92\"               \"grey93\"              \n[355] \"grey94\"               \"grey95\"               \"grey96\"              \n[358] \"grey97\"               \"grey98\"               \"grey99\"              \n[361] \"grey100\"              \"honeydew\"             \"honeydew1\"           \n[364] \"honeydew2\"            \"honeydew3\"            \"honeydew4\"           \n[367] \"hotpink\"              \"hotpink1\"             \"hotpink2\"            \n[370] \"hotpink3\"             \"hotpink4\"             \"indianred\"           \n[373] \"indianred1\"           \"indianred2\"           \"indianred3\"          \n[376] \"indianred4\"           \"ivory\"                \"ivory1\"              \n[379] \"ivory2\"               \"ivory3\"               \"ivory4\"              \n[382] \"khaki\"                \"khaki1\"               \"khaki2\"              \n[385] \"khaki3\"               \"khaki4\"               \"lavender\"            \n[388] \"lavenderblush\"        \"lavenderblush1\"       \"lavenderblush2\"      \n[391] \"lavenderblush3\"       \"lavenderblush4\"       \"lawngreen\"           \n[394] \"lemonchiffon\"         \"lemonchiffon1\"        \"lemonchiffon2\"       \n[397] \"lemonchiffon3\"        \"lemonchiffon4\"        \"lightblue\"           \n[400] \"lightblue1\"           \"lightblue2\"           \"lightblue3\"          \n[403] \"lightblue4\"           \"lightcoral\"           \"lightcyan\"           \n[406] \"lightcyan1\"           \"lightcyan2\"           \"lightcyan3\"          \n[409] \"lightcyan4\"           \"lightgoldenrod\"       \"lightgoldenrod1\"     \n[412] \"lightgoldenrod2\"      \"lightgoldenrod3\"      \"lightgoldenrod4\"     \n[415] \"lightgoldenrodyellow\" \"lightgray\"            \"lightgreen\"          \n[418] \"lightgrey\"            \"lightpink\"            \"lightpink1\"          \n[421] \"lightpink2\"           \"lightpink3\"           \"lightpink4\"          \n[424] \"lightsalmon\"          \"lightsalmon1\"         \"lightsalmon2\"        \n[427] \"lightsalmon3\"         \"lightsalmon4\"         \"lightseagreen\"       \n[430] \"lightskyblue\"         \"lightskyblue1\"        \"lightskyblue2\"       \n[433] \"lightskyblue3\"        \"lightskyblue4\"        \"lightslateblue\"      \n[436] \"lightslategray\"       \"lightslategrey\"       \"lightsteelblue\"      \n[439] \"lightsteelblue1\"      \"lightsteelblue2\"      \"lightsteelblue3\"     \n[442] \"lightsteelblue4\"      \"lightyellow\"          \"lightyellow1\"        \n[445] \"lightyellow2\"         \"lightyellow3\"         \"lightyellow4\"        \n[448] \"limegreen\"            \"linen\"                \"magenta\"             \n[451] \"magenta1\"             \"magenta2\"             \"magenta3\"            \n[454] \"magenta4\"             \"maroon\"               \"maroon1\"             \n[457] \"maroon2\"              \"maroon3\"              \"maroon4\"             \n[460] \"mediumaquamarine\"     \"mediumblue\"           \"mediumorchid\"        \n[463] \"mediumorchid1\"        \"mediumorchid2\"        \"mediumorchid3\"       \n[466] \"mediumorchid4\"        \"mediumpurple\"         \"mediumpurple1\"       \n[469] \"mediumpurple2\"        \"mediumpurple3\"        \"mediumpurple4\"       \n[472] \"mediumseagreen\"       \"mediumslateblue\"      \"mediumspringgreen\"   \n[475] \"mediumturquoise\"      \"mediumvioletred\"      \"midnightblue\"        \n[478] \"mintcream\"            \"mistyrose\"            \"mistyrose1\"          \n[481] \"mistyrose2\"           \"mistyrose3\"           \"mistyrose4\"          \n[484] \"moccasin\"             \"navajowhite\"          \"navajowhite1\"        \n[487] \"navajowhite2\"         \"navajowhite3\"         \"navajowhite4\"        \n[490] \"navy\"                 \"navyblue\"             \"oldlace\"             \n[493] \"olivedrab\"            \"olivedrab1\"           \"olivedrab2\"          \n[496] \"olivedrab3\"           \"olivedrab4\"           \"orange\"              \n[499] \"orange1\"              \"orange2\"              \"orange3\"             \n[502] \"orange4\"              \"orangered\"            \"orangered1\"          \n[505] \"orangered2\"           \"orangered3\"           \"orangered4\"          \n[508] \"orchid\"               \"orchid1\"              \"orchid2\"             \n[511] \"orchid3\"              \"orchid4\"              \"palegoldenrod\"       \n[514] \"palegreen\"            \"palegreen1\"           \"palegreen2\"          \n[517] \"palegreen3\"           \"palegreen4\"           \"paleturquoise\"       \n[520] \"paleturquoise1\"       \"paleturquoise2\"       \"paleturquoise3\"      \n[523] \"paleturquoise4\"       \"palevioletred\"        \"palevioletred1\"      \n[526] \"palevioletred2\"       \"palevioletred3\"       \"palevioletred4\"      \n[529] \"papayawhip\"           \"peachpuff\"            \"peachpuff1\"          \n[532] \"peachpuff2\"           \"peachpuff3\"           \"peachpuff4\"          \n[535] \"peru\"                 \"pink\"                 \"pink1\"               \n[538] \"pink2\"                \"pink3\"                \"pink4\"               \n[541] \"plum\"                 \"plum1\"                \"plum2\"               \n[544] \"plum3\"                \"plum4\"                \"powderblue\"          \n[547] \"purple\"               \"purple1\"              \"purple2\"             \n[550] \"purple3\"              \"purple4\"              \"red\"                 \n[553] \"red1\"                 \"red2\"                 \"red3\"                \n[556] \"red4\"                 \"rosybrown\"            \"rosybrown1\"          \n[559] \"rosybrown2\"           \"rosybrown3\"           \"rosybrown4\"          \n[562] \"royalblue\"            \"royalblue1\"           \"royalblue2\"          \n[565] \"royalblue3\"           \"royalblue4\"           \"saddlebrown\"         \n[568] \"salmon\"               \"salmon1\"              \"salmon2\"             \n[571] \"salmon3\"              \"salmon4\"              \"sandybrown\"          \n[574] \"seagreen\"             \"seagreen1\"            \"seagreen2\"           \n[577] \"seagreen3\"            \"seagreen4\"            \"seashell\"            \n[580] \"seashell1\"            \"seashell2\"            \"seashell3\"           \n[583] \"seashell4\"            \"sienna\"               \"sienna1\"             \n[586] \"sienna2\"              \"sienna3\"              \"sienna4\"             \n[589] \"skyblue\"              \"skyblue1\"             \"skyblue2\"            \n[592] \"skyblue3\"             \"skyblue4\"             \"slateblue\"           \n[595] \"slateblue1\"           \"slateblue2\"           \"slateblue3\"          \n[598] \"slateblue4\"           \"slategray\"            \"slategray1\"          \n[601] \"slategray2\"           \"slategray3\"           \"slategray4\"          \n[604] \"slategrey\"            \"snow\"                 \"snow1\"               \n[607] \"snow2\"                \"snow3\"                \"snow4\"               \n[610] \"springgreen\"          \"springgreen1\"         \"springgreen2\"        \n[613] \"springgreen3\"         \"springgreen4\"         \"steelblue\"           \n[616] \"steelblue1\"           \"steelblue2\"           \"steelblue3\"          \n[619] \"steelblue4\"           \"tan\"                  \"tan1\"                \n[622] \"tan2\"                 \"tan3\"                 \"tan4\"                \n[625] \"thistle\"              \"thistle1\"             \"thistle2\"            \n[628] \"thistle3\"             \"thistle4\"             \"tomato\"              \n[631] \"tomato1\"              \"tomato2\"              \"tomato3\"             \n[634] \"tomato4\"              \"turquoise\"            \"turquoise1\"          \n[637] \"turquoise2\"           \"turquoise3\"           \"turquoise4\"          \n[640] \"violet\"               \"violetred\"            \"violetred1\"          \n[643] \"violetred2\"           \"violetred3\"           \"violetred4\"          \n[646] \"wheat\"                \"wheat1\"               \"wheat2\"              \n[649] \"wheat3\"               \"wheat4\"               \"whitesmoke\"          \n[652] \"yellow\"               \"yellow1\"              \"yellow2\"             \n[655] \"yellow3\"              \"yellow4\"              \"yellowgreen\"         \n\n\n\n\n\nThe color name is placed in quotation marks. Let us make our histogram light blue.\n\nhist(temperature, \nxlab=\"Temperature /?C\", \nmain=\"Soil temperature\", \ncol=\"lightblue\")\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nGenerate 100 random variables with mean 50 and standard deviation 5 and\ngenerate a red histogram. Label the histogram appropriately, assuming that these are data for Maize yield in kilograms per hectare for Chitedze experimental station.\n\n\n\n\n\n\nQQ plots\nThe second type of plot we can look at is the qqplot. This plot is used to check normality of data. It is called by the function qqnorm(). The argument is a vector of data.\n\nqqnorm(temperature)\n\n\n\n\nThe argument for this function is vector data. The sample quantiles are just the data values, plotted in increasing order. The theoretical quantiles are the corresponding values for an ordered set of the same number of variables with the standard normal distribution (mean zero variance 1). This means that, if the data are normal, the qq plot should lie on a straight line. The qqline command adds this line to the plot to help your interpretation\n\nqqnorm(temperature)\nqqline(temperature)\n\n\n\n\nYou can add a plot title using \"main = \"\" as in “histogram and you can change the qqline color if you so wish by adding the col=\"\" argument.\n\nqqnorm(temperature,main=\"QQ plot for random normal temperatures\")\nqqline(temperature, col=\"red\")\n\n\n\n\n\n\n\n\n\n\nExercise: qq plot\n\n\n\n\nGenerate 100 random variables with mean 50 and standard deviation 5 and\ngenerate a qq plot with a 1:1 line.\nLabel it appropriately assuming that these are data for Maize yield in kilograms per hectare for Chitedze experimental station.\n\n\n\n\n\nBox plot\nBox plots give summary of the minimum, first quartile, median, third quartile inter quartile range, maximum and outlier values in your dataset. They are used for univariate data but can be split based on a factorial variable e.g gender. The function that is used to call for a boxplot is boxplot() and the argument is vector data. let us try ploting using the data we generated earlier.\n\nboxplot(temperature)\n\n\n\n\nYou can choose to label your box plot with main title, color and label the axis similar to what we did for histograms. This time however, we label y-axis using ylab argument.\n\nboxplot(temperature, \nylab=\"Temperature /?C\", \nmain=\"Soil temperature\", \ncol=\"lightblue\")\n\n\n\n\nThe thick black line in the centre of the boxplot corresponds to the median value of the data (half the values are smaller, half are larger). The bottom of the box (the blue shaded area) is the first quartile of the data, Q1 (25% of the values are smaller), and the top of the box is the third quartile of the data, Q3 (25% of the values are larger).\nIn exploratory data analysis we call the quantity H = Q3-Q1 the “h-spread”. R calculates what are known as “inner fences” of the data which are at Q1-1.5*H and Q3+1.5*H The “whiskers” above and below the box join the Q1 to the smallest data value inside the inner fences, and Q3 to the largest value inside the inner fences. If there are values outside the inner fences then these appear as points on the plot.\nIt is possible to produce a graph in which separate boxplots are produced for different levels of a factor. As an example, let us assume that the first 50 of the values in data come from soil collected at Liempe and the second 50 are from Domboshava. We can create a factor called \"site\" to reflect this:\n\nsite <- factor(rep(c(\"Liempe\",\"Domboshava\"),each=50))\n\nWe then want to plot our data split by the corresponding site we have sampled. We use the function boxplot() but this time we state that the data is a function of a variable using ~ symbol.\n\nboxplot(temperature ~ site )\n\n\n\n\nFor data stored in a data frame, we can simply provide the variable names and then specify the dataset with the data argument. Let us create a dataframe using the vectors site and data.\n\nTemperature_Data <- data.frame(site = site, \ntemperature = temperature) \n\nwe can now plot boxplots for different levels of the factor “site”.\n\nboxplot(temperature~site, data = Temperature_Data)\n\n\n\n\nThe argument, data = Temperature_Data, tells the function that temperature and site are supplied by the Temperature_Data dataframe. You can choose to add labels to your box plot are earlier mentioned.\n\nboxplot(temperature~site, \nylab=\"Temperature /?C\", \nxlab=\"Sampling site\", \nmain=\"Soil temperature\",\ndata = Temperature_Data)\n\n\n\n\n\n\n\n\n\n\nExercise: Box plot\n\n\n\nThe following R commands will generate a set of random data, simulating 500 measurements of body weight on adult males, and 500 for adult females, These data, and a factor \"gender\" are then written into a dataframe \"body_weight\".\nUsing these data create:\n\ntwo boxplots one for all the weight data combined and\nanother plot that seperates the female and male boxplots.\nlabel the boxplots appropriately.\nare there any outliers in your data?\n\n\n\n\n\nBar plot\nThis allows us to create a bar chart where the heights of the bars are based on the values given by the vector input. The function that is used to call for a barplot is barplot() and the argument is vector data. There are additional options for giving names to each of the bars, for instance, and for coloring the bars, as you have seen for other ealier plots. This function usually works well when you have tabular data. The simplest form for the function barplot() is given below\n\nbarplot(c(3, 9, 5))\n\n\n\n\nAs you can see from your plot, it has no labels and it is therefore difficult to get any information from it. let us create some data of gender count in a population of 100 people using the sample function.\n\ngender <- sample(c(\"F\", \"M\"), size = 100, replace = TRUE)\n\nprint(gender)\n\n  [1] \"F\" \"M\" \"F\" \"M\" \"M\" \"F\" \"M\" \"F\" \"F\" \"F\" \"M\" \"M\" \"F\" \"F\" \"F\" \"M\" \"F\" \"M\"\n [19] \"M\" \"F\" \"F\" \"M\" \"F\" \"F\" \"F\" \"F\" \"F\" \"M\" \"F\" \"F\" \"F\" \"M\" \"F\" \"M\" \"M\" \"M\"\n [37] \"M\" \"F\" \"F\" \"F\" \"F\" \"F\" \"F\" \"M\" \"M\" \"M\" \"M\" \"M\" \"F\" \"F\" \"M\" \"F\" \"F\" \"F\"\n [55] \"M\" \"F\" \"M\" \"F\" \"F\" \"M\" \"M\" \"M\" \"M\" \"M\" \"F\" \"M\" \"M\" \"M\" \"M\" \"F\" \"F\" \"M\"\n [73] \"M\" \"F\" \"F\" \"F\" \"M\" \"F\" \"M\" \"F\" \"M\" \"F\" \"M\" \"F\" \"M\" \"F\" \"M\" \"M\" \"F\" \"F\"\n [91] \"F\" \"F\" \"M\" \"F\" \"F\" \"M\" \"M\" \"M\" \"F\" \"F\"\n\n\nIf you print gender, you notice that it is a vector. However, we need to generate tabular data from the gender vector which shows the gender count for each gender. We do this using the table() function.\n\ngenderCount <- table(gender)\n\nprint(genderCount)\n\ngender\n F  M \n54 46 \n\n\nIf we print genderCount, you see that it is now in a table form. Now we can create the barplot\n\nbarplot(genderCount)\n\n\n\n\nYou can choose to add labels to barplot as earlier mentioned for the previous plots. You can as well change the color of the bars.\n\nbarplot(genderCount, ylab=\"count\", xlab=\"Gender\",col=\"red\",\nmain=\"Number of Females and Males\")\n\n\n\n\nOne thing that you may notice is that the bar for female goes above the y-axis. this means that the default scale for y-axis is not appropriate. we can change this adding an extra argument called ylim. this will be a vector of length 2 that shows the minimum and maximum value of the axis. In this case let us make the range of the axis to be from 0-70.\n\nylim=c(0,70)\n#\n\nbarplot(genderCount,ylim=c(0,70) ,ylab=\"count\", xlab=\"Gender\",\nmain=\"Number of Females and Males\", col= \"red\")\n\n\n\n\n\n\n\n\n\n\nExercise: Bar plot\n\n\n\nThe data below are a simulated sample of 100 locations at which the soil class is identified\n\nSoil_type <- sample(c(\"Alfisol\", \"Oxisol\",\"Vertisol\"), \nsize = 100, replace = TRUE)\n\n\nCreate a bar plot to show the frequency of the three soil types in the sample,\nlabel it and adjust the axis and colour appropriately."
  },
  {
    "objectID": "data_visualisation.html#multivariate-graphs",
    "href": "data_visualisation.html#multivariate-graphs",
    "title": "9  Data Visualisation",
    "section": "Multivariate graphs",
    "text": "Multivariate graphs\nIn this section, we look at graphics that we may create with multiple variables. This is mostly done using the plot(). They are important in checking how two or more variables relate to each other.\n\nPlots\nThe simplest plot() function takes in two arguments. The first argument represents the x-axis while the second argument is the vector of y-axis. Let us create two vectors, one for days and the other for temperature.\n\ndays<-c(1,2,3,4,5,6,7)\n\ntemp<-c(25,28, 30,26,27, 28,26)\n\n# We can plot these two variables to see how temperature varied for different days.\n\nplot(days,temp)\n\n\n\n\nIf you wish, you can specify the x and y variables. This means that the order of these arguments will not matter as you can place them interchangeably.\n\nplot(y=temp, x=days)\n\n\n\n\nFrom the scatter plot, you will notice that, by default,it added axis labels that are simply the names of the objects we passed i.e days and temp and there is no title. All of these things, can be added as previous graphs.\nThe list below shows arguments that can be added to the plot function as discussed already:\n\nxlab=“day”\nylab=“temp”\nmain=“Temperature variations on different days”\nylim=c(24,32)\nxlim=c(1,7)\ncol=“red”\n\n\nplot(y=temp, x=days,\n# x axis label\nxlab=\"day\",\n# y axis label\nylab=\"temp\",\n# title\nmain=\"Temperature variations on different days\",\n# y axis range\nylim=c(24,32),\n# x axis range\nxlim=c(1,7),\n# color\ncol=\"red\" )\n\n\n\n\nIn R, there is a an embedded dataset called iris. This is a famous biological data set with measurements on flowers of different species of iris , often used in multivariate statistics. You can call this data by simply typing “iris” in the console or on a script.\nIris contains data for Sepal Length, Sepal Width, Petal Length and Petal Width. These variables are presented in the columns of the data set, and each row corresponds to a particular individual flower. You can see the exact variable names in the data set with the command\n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nYou can refer to a particular variable in the data set as follows\n\niris[,\"Sepal.Length\"] # notice the subsetting!\n\n  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1\n [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0\n [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5\n [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1\n [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5\n [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3\n[109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2\n[127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8\n[145] 6.7 6.7 6.3 6.5 6.2 5.9\n\n\n.. so, for example, to plot a histogram of Sepal Length, run the hist command as follows\n\nhist(iris[,\"Sepal.Length\"])\n\n\n\n\nUsing these data, create a plot that shows the relation between the Sepal Length and Petal Length. label the plot and adjust axis limits appropriately\n\n\nPlot Symbols\nIn the graphics that we have created so far, we have mostly left the plotting symbol as the default, black, unfilled circle. However, We can change the symbol by using the argument pch.\nYou can change the plotting symbol by asigning a numeric value using = sign. There are two categories of symbols. Those that range from 0 to 20 and from 21 to 25. For the symbols that range from 21 to 25, in addition to being able to set the color, we can also set the fill. The fill of the shapes is actually set with the argument bg, but just like with the argument col, we can assign any color value.\n\nplot(y=temp, x=days,xlab=\"day\",\nylab=\"temp\",\nmain=\"Temperature variations on different days\",\nylim=c(24,32),\nxlim=c(1,7),\ncol=\"red\" ,\npch=17,\n)\n\n\n\n\nLet us change the fill color of the symbol by using the bg argument. Remember that we can only use this when the symbol used ranges from 21 to 25.\n\nplot(y=temp, x=days,xlab=\"day\",\nylab=\"temp\",\nmain=\"Temperature variations on different days\",\nylim=c(24,32),\nxlim=c(1,7),\ncol=\"red\" ,\npch=23,\nbg=\"blue\"\n)\n\n\n\n\nWe can also set the size of the symbols. We do this with the argument cex. This argument is simply a numeric value indicating how many times bigger(or smaller) than the usual size we want our points. The default is 1.\n\nplot(y=temp, x=days,xlab=\"day\",\nylab=\"temp\",\nmain=\"Temperature variations on different days\",\nylim=c(24,32),\nxlim=c(1,7),\ncol=\"red\" ,\npch=23,\nbg=\"blue\",\ncex=2\n)\n\n\n\n\n\n\n\n\n\n\nExercise 3.6\n\n\n\nFrom your previous plot in Exercise 3.5\n\nUpdate plots with different symbols, fill colors and symbol size. You can use any symbol and fill color of your choice.\n\n\n\n\n\n\n\nTip\n\n\n\nNote: not all symbol types accept changing fill color.\n\n\n\n\n\n\nPlot types\nThe plot we have created so far are scatterplots. We can however, use alternative plot types. These may include line plot, step plot and lines with points among others. We can switch our plot to any of these graphics by using the 'type' argument. We pass to this argument one of a series of letters with default is p, to indicate points, but we can also have l, b, c, o,h, s and n.\nLet us generate plot types l, using the days and temp vector.\n\nplot(y=temp, x=days,type=\"l\")\n\n\n\n\n\n\n\n\n\n\nExercise 3.7\n\n\n\n\nCreate different types of plots using the days and vector data you created.\nCreate different types of plot using the days and .\n\n\n\n\n\nType “n” plots\nYou may have noticed that when you used type= \"n\", your plot was blank. There is nothing wrong with your code. type \"n\" is a blank plot. One may ask, why should we have a blank plot? This is useful when one wants to plot data from different sources (which we may want to differentiate) but representing same variables. To demonstrate this, let us create a dataframe called 'data_temp' that has three columns soil_temp, soil_moisture and site\n\nsoil_temp<-rnorm(90,20,1)\nsoil_moisture<-rnorm(90,12,2)\nsite<-rep(c(\"liempe\",\"chitedze\",\"domboshava\"),30)\ndata_temp <- data.frame (soil_temp,soil_moisture,site)\n\nhead(data_temp)\n\n  soil_temp soil_moisture       site\n1  22.30853     12.095263     liempe\n2  21.34969      9.968005   chitedze\n3  20.52631     10.569731 domboshava\n4  20.40485     13.608526     liempe\n5  21.19270     13.771123   chitedze\n6  20.41654     14.690215 domboshava\n\n\nFrom the dataframe data_temp, we can extract the different sites and plot them seperately on the same plot using type \"n\" plot.\n\n# extract liempe data\nliempe_data<-data_temp[data_temp$site==\"liempe\",]\n# extract chitedze data\nchitedze_data<-data_temp[data_temp$site==\"chitedze\",]\n# extract dombashawa data\ndomboshava_data<-data_temp[data_temp$site==\"domboshava\",]\n\nWe can now plot them on the same graph of how soil-temperature varies with soil moisture at the three sites. First we plot the type \"n\" graph and giving it all the necessary labels using dataframe data_temp.\n\nplot(data_temp$soil_moisture,data_temp$soil_temp,xlab=\"Soil moisture\",\nylab=\"Soil temperature\", xlim=c(8,20) ,type=\"n\")\n\n# Now, add the point from different sites giving them different shapes and color\npoints(liempe_data$soil_moisture,liempe_data$soil_temp, pch=15, col=\"red\")\npoints(chitedze_data$soil_moisture,chitedze_data$soil_temp, pch=16, col=\"green\")\npoints(domboshava_data$soil_moisture,domboshava_data$soil_temp, pch=17, col=\"blue\")\n\n\n\n\n\n\n\n\n\n\nExercise 3.8\n\n\n\nFrom your plot in Exercise 3.7 ,Update plots to differentiate the species using symbol type and color, fill colors and symbol size. You can use any symbol and fill color of your choice.\n\n\n\n\n\n\nTip\n\n\n\nNote: not all symbol types accept changing fill color.\n\n\n\n\n\n\nAdding Legend to plot\nAdding a legend to your plot will make your plot easy to translate. From the plot in the previous section, it is not clear what the different colors or shapes represent. A legent provides information for this.The function to use is legend()\nThe first argument to this function is the position of the legend on your plot. This can be done either by using X and Y co-ordinate location or a single string of the form \"topright\", \"bottomright\", \"bottomleft\", \"topleft\", or \"center\" among others.\nWe then need to specify the legend text using legend.text argument. This is a vector of text that will be used to label the legend. The order of the text in the vector should correspond to the order of the points in the plot.\nWe then specify colors, points, and so on, for data added maintaining the ordering.\nLets create the legend for the plot of soil moisture vs temperature at the sites liempe, chitedze and domboshava. Note that a plot must already be active for legend to be used.\n\nplot(data_temp$soil_moisture,data_temp$soil_temp,xlab=\"Soil moisture\",\nylab=\"Soil temperature\", xlim=c(8,20) ,type=\"n\")\n\npoints(liempe_data$soil_moisture,liempe_data$soil_temp, pch=15, col=\"red\")\npoints(chitedze_data$soil_moisture,chitedze_data$soil_temp, pch=16, col=\"green\")\npoints(domboshava_data$soil_moisture,domboshava_data$soil_temp, pch=17, col=\"blue\")\n\nlegend(\"topright\", legend = c(\"Liempe\", \"Chitedze\",\"Domboshava\" ),\npch = c(15,16, 17), col = c(\"red\", \"green\",\"blue\" ))\n\n\n\n\nOne can alternatively use the x,y position on the plot to position the legend\n\nplot(data_temp$soil_moisture,data_temp$soil_temp,xlab=\"Soil moisture\",\nylab=\"Soil temperature\", xlim=c(8,20) ,type=\"n\")\n\npoints(liempe_data$soil_moisture,liempe_data$soil_temp, pch=15, col=\"red\")\npoints(chitedze_data$soil_moisture,chitedze_data$soil_temp, pch=16, col=\"green\")\npoints(domboshava_data$soil_moisture,domboshava_data$soil_temp, pch=17, col=\"blue\")\n\n\nlegend(16,20, legend = c(\"Liempe\", \"Chitedze\",\"Domboshawa\" ),\npch = c(15,16, 17), col = c(\"red\", \"green\",\"blue\" ))\n\n\n\n\n\n\n\n\n\n\nExercise 3.9\n\n\n\nFrom your previous plot in exercise 3.8, add a legend to the Updated plot that differentiate the species using symbol type and color, fill colors and symbol size.\n\n\n\n\nControlling graphical layout\nWhen we create plots, we may want to present them on the same page for easy comparison. This can be done in two ways, firsly, using the par() function and secondly, using layout() function.\n\nUsing par() function\nWe can set up a graphics device using the mfrow argument in the par() function. The argument is a vector of the number of rows and columns into which our device should be split. When we then create graphics, they will be entered into the device across the rows, starting in the top left of the grid.\nAs an example, suppose that we have some random data that we want to plot as a histogram, boxplot, QQ plot, and against its index. Since we have four plots, We set this up as a 2*2 grid plot area, using the par().\n\npar(mfrow = c(2, 2))\n\nThis sets up an empty 2*2 plot area. As you start ploting, the plots will start filling up the plot area. Let us do this by ploting histogram, boxplot, QQ plot, and against its index.\n\npar(mfrow = c(2, 2))\n\nx <- rnorm(100)\nhist(x)\nboxplot(x)\nqqnorm(x)\nplot(x)\n\n\n\n\nOnce you have set up the plotting area, it will remain active untill you set it back to the default by setting mfrow argument to c(1,1).\n\npar(mfrow = c(1, 1))\n\nSometimes when putting graphs together in a panel like this you might find that the individual graphs need adjustments to their format. For example, the y-axis labels \"Frequency\" and \"Sample quantiles\" in the example above are perhaps too close to the edge of the panel. The par command with argument \"mar\" for margins will adjust this by adjusting the margins for each individual graph to 5 lines (bottom), 5 lines (left side), 3 lines (top) and 2 lines (right side).\n\npar(mar=c(5,5,3,3))  \n\nTry calling this par command after par(mfrow=c(2,2))in the example above to see its effect, and experiment with different numbers of lines in the margin. The default setting is c(5, 4, 4, 2) + 0.1 which shows that you can make finer adjustments to the margins than whole numbers of lines.\n\npar(mfrow=c(2,2)) \npar(mar=c(5,5,3,3))\n\nx <- rnorm(100)\nhist(x)\nboxplot(x)\nqqnorm(x)\nplot(x)\n\n\n\n\n\n\nUsing layout() function\nThis allows finer control of the layout of our graphics. It allows you to control the width and height of each of the columns in our graphics device. The main argument is a matrix that specifies the locations for each graphic. Each graphic is represented by an integer value and appears in the grid in all regions where that value appears.\nAs an example, suppose we want to plot four graphics, as in the previous section, but we want the first histogram to take up the entire first row and the other three graphics to appear underneath in one row. In that case, we would create the following matrix\n\nmat <- rbind(1, 2:4)\n\nThus, the first graphic would fill all cells containing the value 1, in this case, the entire first row. The second graphic would appear in the position of the 2, and so on. To set this as our layout, we pass it to the layout() function, followed by the graphics in order. Let us first generate random numbers to work with.\n\nx <- rnorm(100)\n\nlayout(mat)\n\nhist(x)\nboxplot(x)\nqqnorm(x)\nplot(x)\n\n\n\n\n\n\n\n\n\n\nExercise 3.10\n\n\n\nUsing the iris data, generate\n\nhistogram of Sepal Length,\nboxplot of Petal Length,\nqq plot of Petal Width and\na plot of Sepal Length against Petal Length on the same plot area with equal dimensions.\n\n\n\n\n\n\n\n\n\nExercise 3.11\n\n\n\nAdjust, the plot in the previous exercise so that histogram occupies the whole bottom of the plot area and the other three occupy the top of the plot area in equal dimensions.\n\n\n\n\n\nSaving/Printing plots\nNow that we have known how to create graphics, one thing remaining is to print out the ouput. A number of graphics devices are available, including PDF, PNG, JPEG, and bitmap. If we do not specify the device to use, the default device will be opened, and in R this is the Plot tab.\nTo print a graph to pdf ,png and jpeg, one must create the device before ploting the graph. This is done by using the functions\n\npdf(\"name.pdf\")\npng(\"name.pgn\")\njpeg(\"name.jpeg\") \n\nThe argument for these functions is the desired name of the document in quotation marks e.g. pdf(\"myFirstGraphic.pdf\"). When this function is run, the plot tab in R will not appear but a pdf of the graph will be produced in the working directory.\nLet us create a histogram of 100 random numbers and save it as a pdf document.\n\n# Create a pdf device\npdf(\"myFirstGraphic.pdf\")\n\n# Create a histogram of 100 random numbers\nhist(rnorm(100))\n\n# Close the device\ndev.off() \n\nRemember to close the device when done using the dev.off() function, otherwise all your graphics onwards will be pdf documents and not any other device e.g the R plot tab.\n\n\n\n\n\n\nExercise 3.12\n\n\n\nPrint the plot you generated in EXERCISE to a PDF, PNG and JPEG giving it an appropriate name. Remember to close the device"
  },
  {
    "objectID": "basic_statistics.html#import-custom-functions",
    "href": "basic_statistics.html#import-custom-functions",
    "title": "10  Basic statistics",
    "section": "Import custom functions",
    "text": "Import custom functions\n\nsource(\"data/custom_functions/SBStat.R\")\n\nR warm-up, sampling from a remote sensor image and the normal distribution"
  },
  {
    "objectID": "basic_statistics.html#import-data",
    "href": "basic_statistics.html#import-data",
    "title": "10  Basic statistics",
    "section": "Import data",
    "text": "Import data\nFirst, read the image into a data frame.\n\ndataKenya.df<-read.table(\"data/MSS.dat\",header=T)\nhead(dataKenya.df)\n\n  dn\n1 49\n2 52\n3 52\n4 52\n5 52\n6 52\n\n\nThe variable is called \"dn\", the values correspond to reflection of visible red light from pixels in a Landsat MSS image of north-west Kenya"
  },
  {
    "objectID": "basic_statistics.html#explore-the-data",
    "href": "basic_statistics.html#explore-the-data",
    "title": "10  Basic statistics",
    "section": "Explore the data",
    "text": "Explore the data\nCompute a histogram, boxplot and other summary statistics of the data\n\nnames(dataKenya.df)    \n\n[1] \"dn\"\n\nhist(dataKenya.df$dn)\n\n\n\nsumma(dataKenya.df$dn)\n\n       Mean Median Quartile.1 Quartile.3 Variance       SD   Skewness\n[1,] 52.836     57         43         61 131.1566 11.45236 -0.5775254\n     Octile skewness   Kurtosis No. outliers\n[1,]      -0.4666667 -0.9049057            0\n\nsummaplot(dataKenya.df$dn)\n\n\n\n\nWe used the summa() and summaplot() functions from SBStat above. Expand the following boxes to see the code for these functions.\n\n\n\n\n\n\nsumma() function\n\n\n\n\n\n\nprint(summa)\n\nfunction (x, sigf) \n{\n    if (missing(sigf)) {\n        rosig <- F\n    }\n    else {\n        rosig <- T\n    }\n    x <- na.drop(x)\n    Q1 <- quantile(x, prob = 0.25)\n    Q3 <- quantile(x, prob = 0.75)\n    Q2 <- quantile(x, prob = 0.5)\n    hspread <- Q3 - Q1\n    Fu <- Q3 + 3 * hspread\n    Fl <- Q1 - 3 * hspread\n    ols <- which(x < Fl)\n    oll <- which(x > Fu)\n    posols <- which(x < (Q1 - 1.5 * hspread))\n    if (length(posols) == 0) {\n        lw <- min(x)\n    }\n    else {\n        lw <- min(x[-posols])\n    }\n    posoll <- which(x > (Q3 + 1.5 * hspread))\n    if (length(posoll) == 0) {\n        uw <- max(x)\n    }\n    else {\n        uw <- max(x[-posoll])\n    }\n    ol <- c(ols, oll)\n    nol <- length(ol)\n    outp <- matrix(c(mean(x), Q2, Q1, Q3, var(x), sqrt(var(x)), \n        skew(x), ocskew(x), kurt(x), nol), 1, 10)\n    if (rosig == \"TRUE\") {\n        outp <- signif(outp, sigf)\n    }\n    colnames(outp) <- c(\"Mean\", \"Median\", \"Quartile.1\", \"Quartile.3\", \n        \"Variance\", \"SD\", \"Skewness\", \"Octile skewness\", \"Kurtosis\", \n        \"No. outliers\")\n    return(outp)\n}\n<bytecode: 0x000001b708f8d650>\n\n\n\n\n\n\n\n\n\n\n\nsummaplot() function\n\n\n\n\n\n\nprint(summaplot)\n\nfunction (x, varname) \n{\n    x <- na.drop(x)\n    if (missing(varname)) {\n        varname <- \"x\"\n    }\n    Q1 <- quantile(x, prob = 0.25)\n    Q3 <- quantile(x, prob = 0.75)\n    Q2 <- quantile(x, prob = 0.5)\n    hspread <- Q3 - Q1\n    Fu <- Q3 + 3 * hspread\n    Fl <- Q1 - 3 * hspread\n    ols <- which(x < Fl)\n    oll <- which(x > Fu)\n    posols <- which(x < (Q1 - 1.5 * hspread))\n    if (length(posols) == 0) {\n        lw <- min(x)\n    }\n    else {\n        lw <- min(x[-posols])\n    }\n    posoll <- which(x > (Q3 + 1.5 * hspread))\n    if (length(posoll) == 0) {\n        uw <- max(x)\n    }\n    else {\n        uw <- max(x[-posoll])\n    }\n    ol <- c(ols, oll)\n    par(mfrow = c(1, 2))\n    ymax <- max((hist(x, plot = F))$counts)\n    hist(x, main = \"\", col = \"AliceBlue\", xlab = varname, ylim = c(0, \n        (ymax * 1.25)))\n    boxmin <- ymax * 1.1\n    boxmax <- ymax * 1.2\n    boxmid <- ymax * 1.15\n    lines(c(Q1, Q3), c(boxmin, boxmin))\n    lines(c(Q1, Q3), c(boxmax, boxmax))\n    lines(c(Q1, Q1), c(boxmin, boxmax))\n    lines(c(Q3, Q3), c(boxmin, boxmax))\n    lines(c(Q1, lw), c(boxmid, boxmid))\n    lines(c(Q3, uw), c(boxmid, boxmid))\n    lines(c(Q2, Q2), c(boxmin, boxmax), lwd = 2)\n    lines(c(Fu, Fu), c(10, boxmid), lty = 5, col = \"red\")\n    lines(c(Fl, Fl), c(10, boxmid), lty = 5, col = \"red\")\n    qqn <- qqnorm(x, main = \"\", pch = 16)\n    qqline(x)\n    points(qqn$x[ol], qqn$y[ol], pch = 16, col = \"red\")\n    par(mfrow = c(1, 1))\n}\n<bytecode: 0x000001b70c6f6d58>"
  },
  {
    "objectID": "basic_statistics.html#convert-to-a-matrix",
    "href": "basic_statistics.html#convert-to-a-matrix",
    "title": "10  Basic statistics",
    "section": "Convert to a matrix",
    "text": "Convert to a matrix\nNow convert the data to a matrix (128 x 128 pixels)\n\nkenya<-matrix(data=dataKenya.df$dn,nrow=128,ncol=128)"
  },
  {
    "objectID": "basic_statistics.html#plot-the-image",
    "href": "basic_statistics.html#plot-the-image",
    "title": "10  Basic statistics",
    "section": "Plot the image",
    "text": "Plot the image\nThe following command allows you to plot the image\n\nimage(kenya)\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nCan you interpret the image and relate it to the histogram of the data?"
  },
  {
    "objectID": "basic_statistics.html#select-a-sample-size",
    "href": "basic_statistics.html#select-a-sample-size",
    "title": "10  Basic statistics",
    "section": "Select a sample size",
    "text": "Select a sample size\nWe now treat the image as a field to be sampled. Select a sample size n\n\nn<-100"
  },
  {
    "objectID": "basic_statistics.html#sample-the-image",
    "href": "basic_statistics.html#sample-the-image",
    "title": "10  Basic statistics",
    "section": "Sample the image",
    "text": "Sample the image\nThe command SRSimage(n,mat), from SBStat, will draw a simple random sample of size n from a matrix mat, and draw a map showing the sample locations\n\n\n\n\n\n\nSRSimage() function\n\n\n\n\n\n\nprint(SRSimage)\n\nfunction (n, mat) \n{\n    sample <- SRSRect(1, 128, 1, 128, 0, n, mat)\n    return(sample)\n}\n\n\n\n\n\n\n# Draw a sample of size n from the image\nsample<-SRSimage(n,kenya)\n\n\n\n# Plot a histogram of sample locations\nhist(sample)\n\n\n\n# Plot summary stats of the data in the sample\nsumma(sample)\n\n      Mean Median Quartile.1 Quartile.3 Variance       SD   Skewness\n[1,] 52.63     57       40.5         61 136.2961 11.67459 -0.4136408\n     Octile skewness  Kurtosis No. outliers\n[1,]      -0.4285714 -1.163071            0\n\n\n\n\n\n\n\n\nExercise 2: Compare the sample with the whole image\n\n\n\nCompute the mean of the data in your sample, compare it with the mean of the whole image.\n\n\nThe multisample() next command (from SBStat) will draw 1000 samples of size n. It shows the histogram and QQ plot for the 1000 sample means. Expand the following box to see the code for the multisample() function.\n\n\n\n\n\n\nmultisample() function\n\n\n\n\n\n\nprint(multisample)\n\nfunction (n, mat) \n{\n    par(mfrow = c(2, 2))\n    varm <- round(((sd(mat))^2), 2)\n    mmean <- round(mean(mat), 1)\n    lab1 <- paste(\"Variance =\", varm, \" mean= \", mmean)\n    hist(mat, main = lab1, xlab = \"Raw data values\", cex.main = 0.85, \n        cex.lab = 0.9)\n    qqnorm(mat)\n    mv <- vector(\"numeric\", 1000)\n    for (i in 1:1000) {\n        mv[i] <- mean(SRSimage(n, mat))\n        print(i)\n    }\n    varmean <- round(var(mv), 2)\n    mmean <- round(mean(mv), 1)\n    lab2 <- paste(\"Variance =\", varmean, \" mean= \", mmean)\n    lab3 = paste(\"Means of 1000 samples size =\", n)\n    hist(mv, main = lab2, xlab = lab3, cex.main = 0.85, cex.lab = 0.9)\n    qqnorm(mv)\n}\n\n\n\n\n\n\nmultisample(n,kenya)\n\n\n\n\n\n\n\nExercise 3:\n\n\n\nExperiment using different sample sizes and answer the following questions.\n\nWhat links the variance of the data, the variance of the sample mean and the sample size?\nHow does the histogram of the sample means differ from the histogram of the data?\n\n\n\nSome bits of R code to help with understanding of the normal distribution\npnorm(x,mean,sd) gives the probability of a normal random variable\n\n# pnorm(x,mean,sd)\n \npnorm(0.0,0.0,1)\n\n[1] 0.5\n\npnorm(2,0.0,1)\n\n[1] 0.9772499\n\n1-pnorm(1.96,0.0,1)\n\n[1] 0.0249979\n\n\n\n\n\n\n\n\nExercise 4:\n\n\n\nA cider-maker uses a griddle to sort apples, which will remove any with a diameter of less than 4 cm. If apple diameter is normally distributed in a batch, the mean diameter is 7 cm and the standard deviation is 2 cm, what proportion of the batch do you expect to be removed?\nCan you find out (perhaps by trial and error) what griddle size would remove 15% of the apples?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmu<-7\nsd<-2\ngr<-4\n    \n# prob that an apple has a diameter <= gr is\n    \npnorm(gr,mu,sd)\n\n[1] 0.0668072"
  },
  {
    "objectID": "basic_statistics.html#testing-hypotheses-tasting-tea-and-testing-t",
    "href": "basic_statistics.html#testing-hypotheses-tasting-tea-and-testing-t",
    "title": "10  Basic statistics",
    "section": "Testing hypotheses: tasting tea and testing t",
    "text": "Testing hypotheses: tasting tea and testing t\nBong beans come in pods of five. Bong wasps lay their single egg in a bong bean. If the probability of a single bean’s being parasitized is 0.1, what is the probability that a randomly selected pod will contain two parasitised beans?\n\ndbinom(2,5,0.1)\n\n[1] 0.0729\n\n\n\nTasting tea\nWe use the custom Tea_taste function from SBStat. Expand the following box to see the code for the Tea_taste function. :::{.callout-tip collapse=“true”} ## Tea_taste() function\n\nprint(Tea_taste)\n\nfunction (s, N, p0) \n{\n    pv <- round((1 - pbinom((s - 1), N, p0)), 3)\n    message(\"The probability of getting \", s, \" or more successes out of \", \n        N, \" trials\")\n    message(\"where the probability of success in a single trial is \", \n        p0)\n    if (pv >= 0.001) {\n        message(\"is \", pv)\n    }\n    else {\n        message(\"is < 0.001\")\n    }\n}\n\n\n\nN<-20 # number of trials\ns<-15 # number of successes\np0<-0.5 # probability of a success under the null hypothesis\n\nTea_taste(s,N,p0)\n\nThe probability of getting 15 or more successes out of 20 trials\n\n\nwhere the probability of success in a single trial is 0.5\n\n\nis 0.021\n\n\n\n\n\n\n\n\nExercise 5\n\n\n\nIf you ran an experiment with 40 trials, and had 30 successes, do you think that the evidence against the null hypothesis will be the same (given that the proportion of successes is the same?) Use Tea_taste to find out whether you are right\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nN<-40 # number of trials\ns<-30 # number of successes\np0<-0.5 # probability of a success under the null hypothesis\n\nTea_taste(s,N,p0)\n\nThe probability of getting 30 or more successes out of 40 trials\n\n\nwhere the probability of success in a single trial is 0.5\n\n\nis 0.001\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 6\n\n\n\nA device has been invented to detect oestrous in dairy cattle. In a trial with 50 cows, all of which were known to be in oestrus, 35 were identified as such by the device.\n\nState a null hypothesis,\nand test it using the Tea_taste function.\nDoes this show that the device might be useful for dairy farmers?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nH0 OVUTECH is equivalent to random guesswork.\n\nits output is like tossing a coin\n\n\n\nTea_taste(35,50,0.5)\n\nThe probability of getting 35 or more successes out of 50 trials\n\n\nwhere the probability of success in a single trial is 0.5\n\n\nis 0.003"
  },
  {
    "objectID": "basic_statistics.html#t-tests-to-compare-independent-samples",
    "href": "basic_statistics.html#t-tests-to-compare-independent-samples",
    "title": "10  Basic statistics",
    "section": "t-tests to compare independent samples",
    "text": "t-tests to compare independent samples\nWe use the custom T_test() function from SBStat. Expand the following box to see the code for the T_test() function.\n\n\n\n\n\n\nT_test() function\n\n\n\n\n\n\nprint(T_test)\n\nfunction (variable, groups, data) \n{\n    TEST <- t.test(data[, variable] ~ data[, groups], var.equal = T)\n    message(\"\\n t-test to compare independent random samples from two groups\\n \")\n    resids <- (lm(data[, variable] ~ data[, groups]))$residuals\n    par(mfrow = c(1, 2))\n    boxplot(data[, variable] ~ data[, groups], ylab = variable, \n        xlab = groups)\n    mtext(\"Boxplot of values within groups\", side = 3, adj = 0, \n        line = 1)\n    histplot(resids, \"Residuals\")\n    mtext(\"Histogram and boxplot of residuals\", side = 3, adj = 0, \n        line = 1)\n    message(\"Estimated group means\")\n    print(signif(TEST$estimate, digits = 5))\n    message(\"\\n Difference between group means is \", signif(as.numeric(TEST$estimate[1] - \n        TEST$estimate[2]), digits = 4))\n    message(\"\\n 95% confidence interval for this difference is \", \n        signif(as.numeric(TEST$conf.int[1]), digits = 4), \" to \", \n        signif(as.numeric(TEST$conf.int[2]), digits = 4))\n    message(\"\\n The t-statistic is \", signif(TEST$statistic, \n        digits = 5), \" with \", signif(TEST$parameter, digits = 5), \n        \" degrees of freedom\")\n    message(\"\\n The probability of obtaining evidence this strong or stronger\")\n    message(\" if the true difference is zero is \", signif(TEST$p.value, \n        digits = 5))\n}\n\n\n\n\n\n\ndata.df<-read.table(\"data/chicks.dat\",header=T,stringsAsFactors = T)\n\nnames(data.df)\n\n[1] \"Weight.gain\" \"Feed\"       \n\nT_test(variable=\"Weight.gain\",groups=\"Feed\",data=data.df)\n\n\n t-test to compare independent random samples from two groups\n \n\n\nEstimated group means\n\n\n mean in group casein mean in group soybean \n               323.58                246.43 \n\n\n\n Difference between group means is 77.15\n\n\n\n 95% confidence interval for this difference is 29.19 to 125.1\n\n\n\n The t-statistic is 3.3199 with 24 degrees of freedom\n\n\n\n The probability of obtaining evidence this strong or stronger\n\n\n if the true difference is zero is 0.0028692\n\n\n\n\n\n\n\n\n\n\n\nExercise 7\n\n\n\nThe rate of carbon dioxide emission was measured by incubation of soil cores collected from randomly located selections in a region of Bedfordshire from either arable land or grassland\nTest for evidence of a difference between these land uses. - Data: CO2.dat, - land use (arable or grass) and - CO2 emission (micro g C per kg soil per day)\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata.df<-read.table(\"data/CO2.dat\",header=T,stringsAsFactors = T)\n\nnames(data.df)\n\n[1] \"LandUse\" \"CO2\"    \n\nT_test(variable=\"CO2\",groups=\"LandUse\",data=data.df)\n\n\n t-test to compare independent random samples from two groups\n \n\n\nEstimated group means\n\n\nmean in group Arable  mean in group Grass \n              7931.3              18076.0 \n\n\n\n Difference between group means is -10140\n\n\n\n 95% confidence interval for this difference is -14920 to -5365\n\n\n\n The t-statistic is -4.4596 with 18 degrees of freedom\n\n\n\n The probability of obtaining evidence this strong or stronger\n\n\n if the true difference is zero is 0.00030286"
  },
  {
    "objectID": "basic_statistics.html#analysis-of-variance-with-lm",
    "href": "basic_statistics.html#analysis-of-variance-with-lm",
    "title": "10  Basic statistics",
    "section": "Analysis of variance with lm()",
    "text": "Analysis of variance with lm()\n\nExample 1. Data in cabbage.dat\nYields of spring cabbage from plots to which one of four treatments was applied. The allocation of treatments to plots was done at random. Treatments are:\n\nC: Control, no nitrogen applied.\nAS: Nitrogen applied as ammonium sulphate\nAN: Nitrogen applied as ammonium nitrate\nNC: Nitrogen applied as nitrochalk (ammonium nitrate + chalk)\n\n\n# Import data\ndata_ca.df<-read.table(\"data/cabbage.dat\",header=T,stringsAsFactors = T)\n\n# Explore data\nnames(data_ca.df)\n\n[1] \"Treatment\" \"Yield\"    \n\n# (i)  Initial model fit\nmod<-lm(Yield~Treatment,data=data_ca.df)\nmod<-lm(log(Yield)~Treatment,data=data_ca.df)\n\n# (ii) Inspect the residuals \nsumma(mod$residuals)\n\n             Mean       Median  Quartile.1 Quartile.3   Variance         SD\n[1,] 3.252607e-18 -0.008836858 -0.02960795 0.04914689 0.00412858 0.06425403\n       Skewness Octile skewness  Kurtosis No. outliers\n[1,] -0.2250617     -0.02602487 -1.170367            0\n\nsummaplot(mod$residuals)\n\n\n\nplot(mod$fitted.values,mod$residuals,pch=16)\n\n\n\n# (iii)  Test the general or omnibus null hypothesis\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: log(Yield)\n          Df  Sum Sq  Mean Sq F value    Pr(>F)    \nTreatment  3 0.94845 0.316150  61.261 1.513e-07 ***\nResiduals 12 0.06193 0.005161                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nboxplot(Yield~Treatment,data=data_ca.df)\n\n\n\n# Make contrast coefficients\n\ndata_ca.df$C1<--1\ndata_ca.df$C1[which(data_ca.df$Treatment==\"C\")]<-3\n\ndata_ca.df$C2<--1\ndata_ca.df$C2[which(data_ca.df$Treatment==\"C\")]<-0\ndata_ca.df$C2[which(data_ca.df$Treatment==\"AS\")]<-2\n\ndata_ca.df$C3<--1\ndata_ca.df$C3[which(data_ca.df$Treatment==\"C\")]<-0\ndata_ca.df$C3[which(data_ca.df$Treatment==\"AS\")]<-0\ndata_ca.df$C3[which(data_ca.df$Treatment==\"NC\")]<-1\n\nmod<-lm(log(Yield)~Treatment,data=data_ca.df)\nmod2<-lm(log(Yield)~C1+C2+C3,data=data_ca.df)\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: log(Yield)\n          Df  Sum Sq  Mean Sq F value    Pr(>F)    \nTreatment  3 0.94845 0.316150  61.261 1.513e-07 ***\nResiduals 12 0.06193 0.005161                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(mod2)\n\nAnalysis of Variance Table\n\nResponse: log(Yield)\n          Df  Sum Sq Mean Sq  F value  Pr(>F)    \nC1         1 0.92682 0.92682 179.5913 1.4e-08 ***\nC2         1 0.01147 0.01147   2.2234  0.1617    \nC3         1 0.01015 0.01015   1.9677  0.1860    \nResiduals 12 0.06193 0.00516                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nExample 2 Data in cashmore.dat\nThese are data on soil properties from sites in different soil series or classes (the variable \"Soil_Series\", which is read in as a factor).\nUse the LM and ANOVA to examine evidence that differences between the soil series account for variation in water content (GWC_T, GWC_S) and OM content.\nThe soil series are quite distinct, note the following information about them\n\n\n\nSeries Name\nSymbol\nParent\nmaterial\n\n\n\n\nLowlands\nLw\nLower Greensand\nColluvial*\n\n\nHallsworth\nHa\nLower Greensand\nPelostagnogley**\n\n\nNercwys\nNe\nLower Greensand\nStagnogley**\n\n\nEvesham\nEv\nGault Clay\n\n\n\nBardsey\nBa\nGault Clay\n\n\n\nEnborne\nEn\nAlluvial Clay\n\n\n\n\n\nThe colluvial soil is relatively coarse material over the LGS\nThe stagnogleys are finer material, drainage is impeded.\nIn the pelostagnogley the finer minerals are prone to swell when wet and shrink and crack when dry.\nThe Evesham series is formed in heavy clay, the Bardsey series and\nEnborne series are both sandy clay loams over clay loams.\n\n\ndata_csh.df<-read.table(\"data/cashmore.dat\",header=T,stringsAsFactors=T)\n\nnames(data_csh.df)\n\n[1] \"GWC_T\"       \"GWC_S\"       \"pH_T\"        \"pH_S\"        \"OM_T\"       \n[6] \"OM_S\"        \"Soil_Series\"\n\nmod<-lm(log(GWC_S)~Soil_Series,data=data_csh.df)\nsumma(mod$residuals)\n\n              Mean      Median  Quartile.1 Quartile.3    Variance       SD\n[1,] -6.919243e-18 -0.01001593 -0.06312576 0.04554943 0.008789249 0.093751\n     Skewness Octile skewness Kurtosis No. outliers\n[1,] 1.459066    -0.009520071 3.972526            1\n\nsummaplot(mod$residuals)\n\n\n\nplot(mod$fitted.values,mod$residuals,pch=16)\n\n\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: log(GWC_S)\n            Df  Sum Sq Mean Sq F value    Pr(>F)    \nSoil_Series  5 1.73206 0.34641  37.422 < 2.2e-16 ***\nResiduals   94 0.87014 0.00926                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nboxplot(GWC_T~Soil_Series,data=data_csh.df)\n\n\n\nmod<-lm(OM_T~Soil_Series,data=data_csh.df)\nsumma(mod$residuals)\n\n             Mean      Median Quartile.1 Quartile.3  Variance        SD\n[1,] 2.068549e-17 -0.04007519 -0.4489706  0.3897472 0.6811274 0.8253044\n      Skewness Octile skewness Kurtosis No. outliers\n[1,] 0.4573979       0.1044714 1.081736            1\n\nsummaplot(mod$residuals)\n\n\n\nplot(mod$fitted.values,mod$residuals,pch=16)\n\n\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: OM_T\n            Df Sum Sq Mean Sq F value    Pr(>F)    \nSoil_Series  5 21.213  4.2426  5.9142 8.497e-05 ***\nResiduals   94 67.432  0.7174                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nboxplot(OM_T~Soil_Series,data=data_csh.df)"
  },
  {
    "objectID": "basic_statistics.html#regression-analysis-with-lm",
    "href": "basic_statistics.html#regression-analysis-with-lm",
    "title": "10  Basic statistics",
    "section": "Regression analysis with lm()",
    "text": "Regression analysis with lm()\nExample 1.\n\ndata.df<-read.table(\"data/soil.dat\",header=T)\nnames(data.df)\n\n[1] \"clay\"   \"SOC\"    \"pHw\"    \"pHCaCl\"\n\n# Plot pH in CaCl2 against pH in water\nplot(data.df$pHCaCl,pch=16,data.df$pHw,xlab=\"pH in CaCl2\",ylab=\"pH in water\",\nxlim=c(2,8.5),ylim=c(2,8.5))\n\n#Draw the bisector, or 1:1 line\nlines(c(2,8.5),c(2,8.5))\n\n\n\n#Compute the correlation coefficient between the two variables\ncor(data.df$pHCaCl,data.df$pHw)\n\n[1] 0.9788838\n\n\n\n\n\n\n\n\nWhat do you conclude about the relationship between the methods for measuring pH, just from the plot?\n\n\n\n\n\n\n\nRegression model using lm\n\nmod<-lm(pHw~pHCaCl,data=data.df)\nsummary(mod)\n\n\nCall:\nlm(formula = pHw ~ pHCaCl, data = data.df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0231 -0.1284  0.0251  0.1465  0.6679 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.83364    0.10595   7.869 9.09e-13 ***\npHCaCl       0.94646    0.01676  56.457  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2522 on 139 degrees of freedom\nMultiple R-squared:  0.9582,    Adjusted R-squared:  0.9579 \nF-statistic:  3187 on 1 and 139 DF,  p-value: < 2.2e-16\n\n# Assumptions\n\nsumma(mod$residuals)\n\n             Mean     Median Quartile.1 Quartile.3   Variance        SD\n[1,] 1.963886e-17 0.02509984 -0.1284438  0.1465173 0.06314678 0.2512902\n       Skewness Octile skewness Kurtosis No. outliers\n[1,] -0.8745355      -0.1175253 2.275353            1\n\nsummaplot(mod$residuals)\n\n\n\nplot(mod$fitted,mod$residuals,xlab=\"Fitted values\",ylab=\"Residuals\",pch=16)\n\n\n\n\n\n\n\n\n\n\nWhat is the evidence provided from the model about the relationship?\n\n\n\n\n\n\n\n\nDraw the regression line\n\n#First, replot the data\nplot(data.df$pHCaCl,data.df$pHw,pch=16,xlab=\"pH in CaCl2\",ylab=\"pH in water\",\nxlim=c(2,8.5),ylim=c(2,8.5))\n\n# Now, chose a minimum and maximum x value for the line\nminx<-2\nmaxx<-8.5\n\nregline(minx,maxx,mod)\n\n\n\n\n\n\nUsing the regression model for prediction\nNow predict the pH in water for some values in CaCl (these would be new samples for which we only know pHCaCl).\nvalues for prediction: we present a set of 5 values 4.2,5.6,6.4,7.3,8.1\n\n# make a vector of the values for prediction\npHCaCl<-c(4.2,5.6,6.4,7.3,8.1)\n\n# make a dataframe from these values\npHCaCl.df<-data.frame(pHCaCl)\n\n\n\n\n\n\n\nTip\n\n\n\nGive the column in the data frame the same name as the same variable in the data frame we used for the regression.\n\n\n\ncolnames(pHCaCl.df)<-\"pHCaCl\"\n\n\nnames(data.df)\n\n[1] \"clay\"   \"SOC\"    \"pHw\"    \"pHCaCl\"\n\n\nNow make the predictions, the first term is the model object, the second is the data frame with the pH in CaCl2 values for which we want predictions.\n\npHwaterpred<-predict(mod,pHCaCl.df,\ninterval=\"prediction\",level=0.95)\n\nprint(pHwaterpred)\n\n       fit      lwr      upr\n1 4.808759 4.304030 5.313489\n2 6.133798 5.633020 6.634577\n3 6.890963 6.390521 7.391406\n4 7.742774 7.241032 8.244516\n5 8.499939 7.995562 9.004316\n\n\nThe first column is the prediction, the second two are the upper and lower bounds of each 95% confidence interval for a point prediction. Note that this is the confidence interval for a point prediction (i.e. a new single measurement).\n\n\n\n\n\n\nExercise\n\n\n\nThe file cashmore.dat, contains data on a number of soil properties measured at 100 sample sites in an experimental field. These include Gravimetric Water Content in the topsoil (GWC_T) and in the subsoil (GWC_S). It is easier to sample the topsoil than the subsoil.\n\nUse regression analysis to test whether subsoil water content can be predicted from topsoil water content.\n\nFind the predicted subsoil water content for soils where the topsoil water content is 20, 25 and 30%.\nUse regression analysis to test whether subsoil organic matter content can be predicted from topsoil water content. Find the predicted subsoil OM content for soils where the topsoil OM content is 1.5%, 2.5% and 3.5%.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata.df<-read.table(\"data/cashmore.dat\",header=T,stringsAsFactors=T)\n\nnames(data.df)\n\n[1] \"GWC_T\"       \"GWC_S\"       \"pH_T\"        \"pH_S\"        \"OM_T\"       \n[6] \"OM_S\"        \"Soil_Series\"\n\nplot(data.df$GWC_T,data.df$GWC_S,xlim=c(10,35),ylim=c(10,35),pch=16)\nlines(c(15,35),c(15,35))\n\n\n\nmod<-lm(GWC_S~GWC_T,data=data.df)\n\nsumma(mod$residuals)\n\n              Mean    Median Quartile.1 Quartile.3 Variance       SD  Skewness\n[1,] -9.748604e-17 0.0966397  -1.375726   1.061659 3.401231 1.844243 0.7194464\n     Octile skewness Kurtosis No. outliers\n[1,]      -0.1683149 1.718784            0\n\nsummaplot(mod$residuals)\n\n\n\nplot(mod$fitted.values,mod$residuals,pch=16)\n\n\n\nsummary(mod)\n\n\nCall:\nlm(formula = GWC_S ~ GWC_T, data = data.df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7006 -1.3757  0.0966  1.0617  7.0691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.52161    1.20180   0.434    0.665    \nGWC_T        0.84365    0.05331  15.826   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.854 on 98 degrees of freedom\nMultiple R-squared:  0.7188,    Adjusted R-squared:  0.7159 \nF-statistic: 250.5 on 1 and 98 DF,  p-value: < 2.2e-16\n\nGWC.T<-c(20,25,30)\nGWC.T.df<-data.frame(GWC.T)\ncolnames(GWC.T.df)<-\"GWC_T\"\n\nGWC.S.Pre<-predict(mod,GWC.T.df,interval=\"prediction\",level=0.95)\nGWC.S.Pre\n\n       fit      lwr      upr\n1 17.39469 13.69005 21.09932\n2 21.61296 17.90492 25.32099\n3 25.83123 22.04517 29.61728"
  },
  {
    "objectID": "jura.html",
    "href": "jura.html",
    "title": "11  Basic Statistics: Jura",
    "section": "",
    "text": "Exercise: Exploratory data analysis\n\n\n\nRun the blocks below and: i) Discuss the summary statistics and distributions i) Carry out the transformations and discuss the results\n\n\n\nImport custom functions\n\nsource(\"data/custom_functions/CEPHaStat_3.R\")\n\nCEPHaStat version  3\n\nCEPHaStat is a collection of R functions produced by the UKRI GCRF\nCEPHaS project.  The functions relate primarily to statistical analysis of\nsoil and related data from agricultural and environmental surveys and \nexperiments.  The CEPHaStat file can be shared as it stands, and is made \navailable to all for use, without warranty or liability.\n\nsource(\"data/custom_functions/boxcox.R\")\n\n\n\nImport Jura data\n\ndata.df<-read.csv(\"data/Jura.csv\",header=T,stringsAsFactors=T)\n\n\n\nJura Pb Analyses\n\nDistributions and Summary statistics\n\nsumma(data.df$Pb)\n\n         Mean Median Quartile.1 Quartile.3 Variance       SD Skewness\n[1,] 54.63097   46.8      36.32       60.2 1095.473 33.09793 3.333395\n     Octile skewness Kurtosis No. outliers\n[1,]        0.360807 15.52776           15\n\nsummaplot(data.df$Pb,\"Pb /ppm\")\n\n\n\n\n\n\n\n\n\n\nRemember to base transformations on residuals, after fitting the model!\n\n\n\n\n\n\n\nmod<-lm(Pb~Rock,data=data.df)\nsumma(mod$residuals)\n\n             Mean Median Quartile.1 Quartile.3 Variance       SD Skewness\n[1,] 9.108796e-16  -7.78     -17.38   6.517188 1050.191 32.40665 3.281825\n     Octile skewness Kurtosis No. outliers\n[1,]       0.3353765 15.35796           15\n\nsummaplot(mod$residuals,\"Residual /ppm Pb\")\n\n\n\n\n\n\nComparing the log and BoxCox transformations\n\n\n\n\n\n\nRemember to base transformations on residuals, after fitting the model!\n\n\n\n\n\n\n\n\nlog transformation\n\nmod2<-lm(log(Pb)~Rock,data=data.df)\nsumma(mod2$residuals)\n\n             Mean      Median Quartile.1 Quartile.3 Variance       SD  Skewness\n[1,] -2.17082e-18 -0.06159088 -0.2847344  0.2183972  0.18418 0.429162 0.9593089\n     Octile skewness Kurtosis No. outliers\n[1,]       0.1468736 1.601836            1\n\nsummaplot(mod2$residuals,\"Residual /Bcox ppm Pb\")\n\n\n\nanova(mod2)\n\nAnalysis of Variance Table\n\nResponse: log(Pb)\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nRock        4  4.501 1.12524  6.0412 0.0001033 ***\nResiduals 354 65.936 0.18626                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nBoxCox transformation\n\nmod3<-lm(BoxCox(Pb)~Rock,data=data.df)\nsumma(mod3$residuals)\n\n             Mean        Median  Quartile.1 Quartile.3    Variance         SD\n[1,] 1.176937e-18 -0.0008966433 -0.02660468 0.02671777 0.001746455 0.04179061\n      Skewness Octile skewness  Kurtosis No. outliers\n[1,] 0.0700563     -0.00527555 0.2274982            0\n\nsummaplot(mod3$residuals,\"Residual /Bcox ppm Pb\")\n\nanova(mod3)\n\nAnalysis of Variance Table\n\nResponse: BoxCox(Pb)\n           Df  Sum Sq   Mean Sq F value    Pr(>F)    \nRock        4 0.05064 0.0126589  7.1673 1.472e-05 ***\nResiduals 354 0.62523 0.0017662                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCo analyses\n\nsumma(data.df$Co)\n\n         Mean Median Quartile.1 Quartile.3 Variance       SD   Skewness\n[1,] 9.437855   9.84       6.66       12.1  12.7388 3.569146 -0.1772374\n     Octile skewness   Kurtosis No. outliers\n[1,]      -0.2240803 -0.6140086            0\n\nsummaplot(data.df$Co,\"Co /ppm\")\n\n\n\nmod<-lm(Co~Rock,data=data.df)\n\nsumma(mod$residuals)\n\n             Mean    Median Quartile.1 Quartile.3 Variance       SD   Skewness\n[1,] 2.561148e-17 -0.166129  -1.842105   1.993871 8.783506 2.963698 -0.1539231\n     Octile skewness  Kurtosis No. outliers\n[1,]        0.115346 0.8231184            0\n\nsummaplot(mod$residuals,\"Residual /ppm Co\")\n\n\n\n\n\n\n\n\n\n\nWhat do you conclude from the Co analysis?"
  },
  {
    "objectID": "intro.html#downloading-and-installing-r-and-rstudio",
    "href": "intro.html#downloading-and-installing-r-and-rstudio",
    "title": "1  Introduction",
    "section": "Downloading and Installing R and Rstudio",
    "text": "Downloading and Installing R and Rstudio\n\n\nDownloading and Installing R\n\nTo download R, you can visit the official R website at https://cran.r-project.org/. On the website, you will see links to download the latest version of R for Windows, Mac, and Linux. Once you have downloaded the installer for your operating system, you can run the installer and follow the prompts to install R on your computer.\nDownloading and installing R:\n\n\n\n\n\n\nInstructions for downloading and Installing R\n\n\n\n\n\nStep 1:\n\nStep 2:\n\nStep 3:\n\nStep 4:\n\nStep 5:\n\nStep 6:\n\nStep 7:\n\nStep 8:\n\n\n\n\n\n\nDownloading and Installing RStudio\nTo download RStudio, you can visit the official RStudio website at https://rstudio.com/products/rstudio/download/. On the website, you will see links to download the latest version of RStudio for Windows, Mac, and Linux. Once you have downloaded the installer for your operating system, you can run the installer and follow the prompts to install RStudio on your computer. \n\n\n\n\n\n\nInstructions for downloading and Installing Rstudio\n\n\n\n\n\nStep 1: Navigate to https://posit.co/download/rstudio-desktop/\n\nStep 2:\n\nStep 3:\n\nStep 4:\n\n\n\n\nPlease note that these are general instructions for a Microsoft Windows operating system, and depending on your system setup and security settings, some steps might be slightly different. Also, you will need to make sure that you have administrative access or permission to install the software on your computer.\nYou can also refer to the software website instruction or online tutorials that are specific to your operating system and setup.\nFrom here we will use the term R to refer to R and Rstudio or vice-versa.\n\n\n\nSource: https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html"
  },
  {
    "objectID": "intro.html#recommended",
    "href": "intro.html#recommended",
    "title": "1  Introduction",
    "section": "Recommended",
    "text": "Recommended"
  },
  {
    "objectID": "intro.html#recommended-set",
    "href": "intro.html#recommended-set",
    "title": "1  Introduction",
    "section": "Recommended set",
    "text": "Recommended set\nStep 1: Download the training files from the following link: https://dzvoti.github.io/mapsR/mapsR-Training.zip\nStep 2: Unzip the file and save it in a folder on your computer.\nStep 3: Open RStudio create a new project using an existing folder. Select the folder where you saved the training files."
  },
  {
    "objectID": "timetable.html#timetable",
    "href": "timetable.html#timetable",
    "title": "Materials and Timetable",
    "section": "Timetable",
    "text": "Timetable\n\n\n\n\n\n\n\n\n\nDate\nSession\nTopics\nFacilitator\n\n\n\n\nMon 27-03-2023\nMorning session\nIntroduction to R and Rstudio\nLiberty Mlambo\n\n\n\n\nData types and structures\nDr Hakunawadi Pswarayi\n\n\n\nAfternoon session\nData wrangling (with Chapter 7 homework)\nDr Chris Chagumaira\n\n\n\n\n\n\n\n\nTue 28-03-2023\nMorning session\nDeveloping custom functions in R\nLiberty Mlambo\n\n\n\nAfternoon session\nSummary statistics and data visualization\nDr Hakunawadi Pswarayi\n\n\n\n\n\n\n\n\nWed 29-03-2023\nMorning & Afternoon session\nBasic Modelling in R\nProf Murray Lark"
  },
  {
    "objectID": "timetable.html#materials",
    "href": "timetable.html#materials",
    "title": "Materials and Timetable",
    "section": "Materials",
    "text": "Materials\nDownload training Materials from google drive here. Note that this is a zipped folder which will require you to unzip it before you can access the files.\nIf you are using a Mac, you can unzip the folder by double clicking on the folder and then right clicking on the folder and selecting “Open with Archive Utility”. If you are using a PC, you can unzip the folder by right clicking on the folder and selecting “Extract All”."
  },
  {
    "objectID": "intro.html#recommended-setup-while-using-this-book",
    "href": "intro.html#recommended-setup-while-using-this-book",
    "title": "1  Introduction",
    "section": "Recommended setup while using this book",
    "text": "Recommended setup while using this book\nStep 1: Download the training files from the following link: https://dzvoti.github.io/mapsR/mapsR-Training.zip\nStep 2: Unzip the file and save it in a folder on your computer.\nStep 3: Open RStudio create a new project using an existing folder. Select the folder where you saved the training files."
  }
]